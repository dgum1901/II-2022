---
title: "Examen 2 de Modelos lineales"
author: "Maria Jose Corea"
date: "2022-12-01"
output: html_document
---

## Ejercicio 2.8 El registro de varvas glaciales representando en la Figura 2.6 exhibe cierta no estacionaridad que pude mejorarse transformandolo a logaritmos y algunos datos adicionales a la no estacionalidad que se puede corregir diferenciado los logaritmos.

(a) Argumente que la serie de varvas glaciales, digamos $x_t$ exhibe heteroeslasticidad por calcular la varianza muestral sobre la primera mitad de los datos. Argumente que la transformación $y_t=log x_t$ estabiliza la varianza sobre la serie. Trace los histogramas de $x_t$ e $y_t$ para ver si la aproximación a la normalidad se mejora transformando los datos.

Solución

(a) La varianza en la segunda mitad de la serie de varvas es obviamente mayor que la de la primera mitad. Dividiendo los datos a la mitad dan $γ_x(0)$ = 133, 594 para la primera y segunda parte respectivamente y la varianza es aproximadamente 4,5 veces más grande en la segunda mitad. La serie transformada $y_t$ = ln xt tiene $γ_y(0)$ = .27, .45 para las dos mitades, respectivamente, y la varianza de la segunda mitad es solo alrededor de 1,7 veces mayor. Los histogramas, calculados para las dos series de la figura 2.1, indican que la transformación mejora la aproximación normal.

```{r}
library(astsa)
data(varve)
data(oil)
634/2
317
varv1 = varve[1:317]
varv2 = varve[318:634]
var(varv1) # = 133.4574
var(varv2) # = 594.4904
var(log(varv1)) # = 0.2707217
var(log(varv2)) # = 0.451371
par(mfrow=c(1,2))
hist(varve)
hist(log(varve))
```
Logró acomodar mejor los datos. Es mejor ajuste.
(b) Trace la serie $y_t$ ¿Existen intervalos de tiempo del orden de 100 años donde se puede observar un comportamiento comparable al observado en el mundo de los registros de temperatura en la figura 1.2?
```{r}
plot(log(varve)) 
```
Estamos comparando dos bases que aparentan correlación. Se observa que no hay estacionalidad 

Los datos entre 300 y 450 muestran una tendencia positiva que es similar a los datos de temperatura global.
(Presumiblemente, esto se debe a una diferencia en la rotación de la Tierra).

(c) Examine la muestra ACF de $y_t$ y comente.
ElACF noa ayuda distinguir la correlaciones a laos ditiontos lags, y nos ayuda a distinguir un posible modelo MA, la dependencia anterior de los recios, correlacion correspecto a los otros lags, la dependencia de los residuos pasados (MA, ES LA CORRELACION CON LOS RESIDUOS PASADOS) si uno quiere ver el modelo AR(Es la correlacion a los mismo observación, no a los residuos del pasado) PACF es el que hace (modela) AR
```{r}
acf(log(varve)) 
```

Aún no podemos diferenciar un ruido blanco puesto que la serie de tiempo no cae exponencialmente a la banda. Se observa una alta correlación en el primer lag, y esto se debe a que se sabe que siempre va a haber alta correlación asimismo. Se observa alta correlación entre los meses.
El ACF de yt es positivo para una gran cantidad de rezagos y disminuye de forma lineal.

(d) Calcule la diferencia $u_t=y_t-y_{t-1}$ examine su gráfica de los datos de varva registrados produce una serie razonablemente estacionario.¿Puedes pensar en una interpretación práctica para Utah? Pista: Para |p| cerca de cero, log(1+p)$\approx$p: sea

$$P=\dfrac{y_t-y_{t-1}}{y_{t-1}}$$
```{r}

u_t <- diff(log(varve))
par(mfrow=c(2,1))
plot(u_t) 
abline(h = 0, col="red")
acf(u_t, lag.max = 50) 



rhos <- acf(u_t)
rhos$acf[2] # rho(1)

#varianza*n-1/n

round(var(u_t) *( (length(varve)-1)/ length(varve)), 4)#gamma(0)=varianza

u = as.numeric(u_t)
round(sum((u-mean(u))^2)/length(u), 4)#gamma(0)

```


 La argumentación de estacionario viene de que la media es masomenos constante a lo largo de la serie (cero) y que la varianza también es constante
La aplicación práctica es que como ver rendimiento logaritmicos o tasa de  crecimiento de un punto a otro por lo de que Se observan volatilidades


2.10.
a) Trace los datos en el mismo gráfico. ¿Cuál de las series simuladas mostradas en
Sección 1.2 ¿A qué se parecen más estas series? ¿Crees que las series son estacionarias?
(Explica tu respuesta)?

```{r}
data(gas)
ts.plot(oil, gas, col=1:2)

```
Se asemejan las series de tiempos, No parecen estacionarias por los picos.

b)En economía, a menudo es el cambio porcentual en el precio (denominado tasa de crecimiento o
retorno), en lugar del cambio de precio absoluto, eso es importante. Argumentar que un
la transformación de la forma yt = ∇ log xt podría aplicarse a los datos, donde xt
es la serie de precios del petróleo o del gas.
c) Transforme los datos como se describe en la parte (b), trace los datos en el mismo gráfico, observe
en los ACF de muestra de los datos transformados y comente.

Respuesta de b y c
```{r}
u_t1 <- diff(log(gas))
par(mfrow=c(2,1))
plot(u_t1) 
abline(h = 0, col="red")
acf(u_t1, lag.max = 50) 
rhos <- acf(u_t1)
```
```{r}
u_t2 <- diff(log(oil))
par(mfrow=c(2,1))
plot(u_t1) 
abline(h = 0, col="red")
acf(u_t1, lag.max = 50) 
rhos <- acf(u_t1)
```

```{r}
ts.plot(u_t1,u_t2)
abline(h = 0, col="red")

```
Se observa una media concentrada en 0, pero picos de volatilidad, lo cual significa que no hay estacionalidad.La serie transformada parece estacionaria y hay muy poco la autocorrelación que queda después de la transformación, por lo que una caminata aleatoria parece plausible para cada serie.

Eso se puede verificar

```{r}
data(gas)
data(oil)
545/2
317
gas1 = gas[1:272]
gas2 = gas[273:545]
var(gas1) 
var(gas2)
var(log(gas1)) 
var(log(gas2)) 
```

```{r}

oil1 = oil[1:272]
oil2 = oil[273:545]
var(oil1) 
var(oil2)
var(log(oil1)) 
var(log(oil2)) 

```
```{r}
poil = diff(log(oil))
pgas = diff(log(gas))
ts.plot(poil, pgas, col=1:2)
acf(poil)
acf(pgas)

```

Parece que de fijo si hay estacionalidad en gas y con oil está la variabilidad un poco distanciadas, pero parece que no son similares entre ambas mitades pero no iguales.

d)Trace el CCF de los datos transformados y comente El pequeño, pero significativo
los valores cuando el gas lleva al petróleo pueden considerarse como retroalimentación.
Existen algunos valores muy extremos [se indica a los estudiantes que observen los valores atípicos en la parte (e)]. Las dos series parecen ser moviéndose al mismo tiempo [esto se enfatiza en las partes (d) y (e)].



```{r}
ccf(poil, pgas)
# corr[poil(t+Lag), pgas(t)] 
```
En este ejemplo nos está interesanto el gas, por eso poil está en la primera entradas, son todos los lags respeto a gas

Existe una fuerte correlación cruzada en el desfase cero [.66] y el poil una semana más adelante [.18]. También hay
retroalimentación para pgas tres semanas antes [.17]. Como se indica en la sugerencia, ccf(poil, pgas) tiene aceite líder
para valores negativos de Lag; es decir, R calcula corr[poil(t+Lag), pgas(t)] para Lag = 0, ±1, ±2,
Tambien se nota los periodos de mayor volatilidad, pero se ve que la media anda en cero, en general parece que puede no haber una estacionalidad, puesto que depende algo adicional

e)Mostrar diagramas de dispersión de la serie de tasas de crecimiento del petróleo y el gas durante un máximo de tres semanas del tiempo de entrega de los precios del petróleo; incluir un suavizador no paramétrico en cada gráfico y Comente los resultados (p. ej., ¿hay valores atípicos? ¿Las relaciones son lineales?).
```{r}
install.packages('astsa')
  library('astsa')
 lag2.plot(poil, pgas, 3)
```

Aparte de los valores atípicos extremos antes mencionados (10-30% de cambios en los precios del petróleo/gas en una semana), los datos parecen bastante lineal. Además, puede haber alguna asimetría observada en el gráfico de retraso 1, pero esta apariencia podría ser causada por valores atípicos.
Lo que se observa es la alta correlación en entre ambas(lag=0) y que en la tercera también es fuerte dicha relación
 Pero sirve más que nada para identificar eso
Y la pasar al punto que sigue que es que en el 1 y 3 son muy fuertes, después del lag 0, evidentemente


f) Ha habido una serie de estudios que cuestionan si los precios de la gasolina responden más rápido cuando los precios del petróleo están subiendo que cuando los precios del petróleo están cayendo ("asimetría"). Intentaremos explorar esta cuestión aquí con una regresión retardada simple; ignoraremos algunos problemas obvios, como valores atípicos y errores autocorrelacionados, por lo que este no será un análisis definitivo. Sean Gt y Ot el gas y el petróleo las tasas de crecimiento.

(i) Ajuste la regresión (y comente los resultados)
Gt = α1 + α2It + β1Ot + β2Ot−1 + peso, donde It = 1 si Ot ≥ 0 y 0 en caso contrario (It es el indicador de no crecimiento o
crecimiento positivo del precio del petróleo). Insinuación:

```{r}
poil = diff(log(oil))
pgas = diff(log(gas))
indi = ifelse(poil < 0, 0, 1)
mess = ts.intersect(pgas, poil, poilL = lag(poil,-1), indi)
summary(fit <- lm(pgas~ poil + poilL + indi, data=mess))

```

Observe que no hay valores significativos

(ii) ¿Cuál es el modelo ajustado cuando hay un crecimiento negativo en el precio del petróleo en el momento
t? ¿Cuál es el modelo ajustado cuando no hay crecimiento o hay un crecimiento positivo en el precio del petróleo?
¿Estos resultados apoyan la hipótesis de la asimetría?

Note −0.006445 + 0.012368 = .006. Hence, the two models are
Gˆt = −.006 + .68Ot + .11Ot−1 if Ot < 0
Gˆt = .006 + .68Ot + .11Ot−1 if Ot ≥ 0
No hay asimertría para estos datos

(iii) Analizar los residuos del ajuste y comentar.


```{r}
plot.ts(resid(fit)) 
 acf(resid(fit)) 
```
Se ajusta muchísimo mejor, excepto por los outliers.



3.22 Genere n = 50 observaciones a partir de un modelo Gaussiano AR(1) con φ = 0.99 y σw = 1. Usando una técnica de estimación de su elección, compare la distribución asintótica aproximada de su estimación (la que usaría para inferencia) con los resultados de un experimento de arranque (utilice B = 200).

A continuación se muestra el código R para este ejemplo usando Yule-Walker. La distribución asintótica es normal con media .99 y error estándar p(1 − .992)/50 ≈ .02. La distribución de arranque debe ser muy diferente a la distribución asintótica. (Si los estudiantes usan MLE, puede haber problemas porque φ está muy cerca del límite.Puede alertar a los alumnos sobre este hecho o dejar que lo averigüen por sí mismos).

```{r}
set.seed(666)

x = arima.sim(list(ar=.99), n=50)
fit = ar.yw(x, order=1)#.yw por .mle
m=fit$x.mean
phi = fit$ar # estimate of phi
nboot = 200 # number of bootstrap replicates
resids = fit$resid[-1] # the first resid is NA
x.star = x # x[1] stays the same throughout
phi.star = rep(NA, nboot)
for (i in 1:nboot) {
resid.star = sample(resids, replace=TRUE)
for (t in 1:49) 
  x.star[t+1] = phi*x.star[t] + resid.star[t]
phi.star[i] = ar.yw(x.star, order=1)$ar #.yw por .mle
}
summary(phi.star); 
hist(phi.star);
stem(phi.star) # and so on ..
```
El objetivo es ver, que hay la approx lineal es mala idea por muestras pequeñas, con bootraping es una tecnica que le perimte utilizar técnica, modelar la distribución del error, sin tomar un supuesto paramétrico, se ven los supuestos de la normalidad, no es tan buena idea, entonces no es correcto usar la ml, ent mejor usar #.yw, se observa en el histograma.

3.34 Ajuste un modelo ARIMA(p, d, q) a la serie de dióxido de azufre, so2, realizando todos
de los diagnósticos necesarios. Después de decidirse por un modelo apropiado, pronostique el
datos en el futuro cuatro períodos de tiempo por delante (alrededor de un mes) y calcular el 95%
intervalos de predicción para cada uno de los cuatro pronósticos. Comentario. (El dióxido de azufre es uno
de los contaminantes monitoreados en el estudio de mortalidad descrito en el Ejemplo 2.2.)

Hay tendencia, por lo que consideramos la (primera) serie diferenciada, que parece estacionaria. Investigación de la ACF y PACF de los diferenciados sugieren un modelo ARMA(0,1) o ARMA(1,1). Montaje de un ARIMA(0,1,1) y ARIMA(1,1,1) a los datos originales indica el modelo ARIMA(0,1,1); el parámetro AR no es significativo en el ajuste ARIMA(1,1,1). Los residuos parecen ser (en el límite) blancos, pero no normales; hay numerosos valores atípicos Ajustar ARIMA (0,1,1) a log (so2) elimina los valores atípicos, pero no cambia nada notablemente
más.

```{r}
data(so2)
plot(so2); 
plot(log(so2))
plot(diff(so2))
plot(diff(log(so2)))
plot(diff(so2))
plot(diff(log(so2)))
acf2(diff(so2)) 
acf2(diff(log(so2)))
#AR--->pacf
sarima(so2,1,0,0) 
sarima(log(so2),1,0,0)
sarima.for(so2,4,1,0,0) 
sarima.for(log(so2),4,1,0,0)
#MA--->acf
sarima(so2,0,0,1) 
sarima(log(so2),0,0,1)
sarima.for(so2,4,0,0,1) 
sarima.for(log(so2),4,0,0,1)
#ARMA
sarima(so2,1,0,1) 
sarima(log(so2),1,0,1)
sarima.for(so2,4,1,0,1) 
sarima.for(log(so2),4,1,0,1)
#ARIMA
majo<-sarima(so2,0,1,1) 
majo1<-sarima(log(so2),0,1,1)
pmajo<-sarima.for(so2,4,0,1,1) 
pmajo1<-sarima.for(log(so2),4,0,1,1)
majo1$fit
majo1$fit

#ARIMA
majoo<-sarima(so2,1,1,1) 
majooo<-sarima(log(so2),1,1,1)
sarima.for(so2,4,1,1,1) 
sarima.for(log(so2),4,1,1,1)
majoo$fit
majooo$fit
#AIC MAS BAJO, MEJOR MODELO
```
Por aic es mejor el modelo ARIME(0,1,1)
```{r}
#sarima(so2,1,1,1) 
#sarima(log(so2),1,1,1)
#sarima.for(so2,4,1,1,1) 
#sarima.for(log(so2),4,1,1,1)
```


```{r}

acf2(diff(so2), max.lag=2*52)
```

3.35 Sea St los datos de ventas mensuales en ventas (n = 150), y sea Lt el indicador líder en adelanto.

(a) Ajuste un modelo ARIMA a St , los datos de ventas mensuales. Analice el ajuste de su modelo paso a paso, presentando su (A) examen inicial de los datos, (B) transformaciones, si es necesario, (C) identificación inicial de los órdenes de dependencia y el grado de diferenciación, (D) parámetro estimación, (E) diagnóstico residual y elección del modelo.

```{r}
plot(sales)
```
parece una caminata aleatoria, por lo que la diferencia d = 1, (puede hacer esto con log(sales) pero no es necesario).

```{r}
acf2(diff(sales)) 
```
Tanto ACF como PACF siguen, así que elija p = q = 1 

```{r}
sarima(sales,0,1,1, no.constant=TRUE)
sarima(sales,1,1,1, no.constant=TRUE)
```

Note que encaja bien, a direncia de un ARIMA(0,1,1)

(b) Use el CCF y las gráficas de retardo entre $\triangledown S_t$ y $ \triangledown L_t$ argumentar que una regresión de $\triangledown S_t$ en $\triangledown L_{t-3}$$ es razonable. [Tenga en cuenta que en lag2.plot(), la primera serie nombrada es la que se retrasa.]


```{r}
data(sales)
data(lead)
ccf(diff(sales),diff(lead))
```

```{r}
lag2.plot(diff(lead), diff(sales),8)
```
ccf(diff(sales),diff(lead)) y lag2.plot(diff(lead), diff(sales),8) sugieren que existe una fuerte relación lineal entre diff(sales) y lag(diff(lead),-3).
```{r}
lag2.plot
```

Tambien lag2.plot muestra una fuerte relación lineal.


(c) Ajuste el modelo de regresión $\triangledown S_t= \beta _0 + \beta _1 \triangledown L_{t−3} + x_t$, donde $x_t$ es un proceso ARMA (explique cómo decidió su modelo para $x_t$). Discuta sus resultados. [Consulte el Ejemplo 3.45 para obtener ayuda sobre la codificación de este problema.]

Después de ajustar la regresión, ACF y PACF indican un AR(1) para los residuos, que se ajusta bien.



```{r}
u = ts.intersect(diff(sales), lag(diff(lead),-3))
ds = u[,1]
dl3 = u[,2]
(fit1 = lm(ds~dl3)) # beta1hat is highly significant
acf2(resid(fit1)) # => an AR(1) for the residuals
(fit2 = sarima(ds, 1,0,0, xreg=dl3)) # reg with ar1 errors
plot(resid(fit2$fit))
acf2(resid(fit2$fit))
```

3.42 Ajuste un modelo ARIMA estacional de su elección a los datos de desempleo en UnempRate. Utilice el modelo estimado para pronosticar los próximos 12 meses.

Este conjunto de datos es una actualización de unemp, pero en términos de porcentaje de desempleados. Las técnicas son las mismas que en el problema anterior y el modelo es casi el mismo; se necesita un parámetro MA adicional

```{r}

#> ?unemp
#frequency(unemp)
data("unemp")
plot(unemp)
acf2(unemp,max.lag = 60)
plot(diff(unemp))
acf2(diff(unemp),max.lag = 60)
acf2(diff(diff(unemp),lag = 12), 60)
sarima(UnempRate, p=2, d=1, q=1, P=0, D=1, Q=1,S= 12)
sarima.for(UnempRate, n.ahead = 12, p=2,d= 1,q= 1,P= 0,D= 1,Q= 1,S= 12)
```




EJERCICIOS CAPITULO 4

4.10  Los niveles de concentración de sal que se sabe que ocurrieron sobre las filas, correspondientes a los niveles de temperatura promedio para los datos de la ciencia del suelo considerados en la Figura 1.18 y la Figura 1.19, están en salt y saltemp . Trace la serie y luego identifique las frecuencias dominantes realizando análisis espectrales separados en las dos series. Incluya intervalos de confianza para las frecuencias dominantes e interprete sus hallazgos


```{r}
data(saltemp)
par(mfrow=c(2,1)) # for CIs, remove log="no" below
mvspec(saltemp, taper=0, log="no")
abline(v=1/16, lty="dashed")
mvspec(salt, taper=0, log="no")
abline(v=1/16, lty="dashed")

```
un procedimiento de estimación espectral no paramétrico el kernel d daniel
perilograma, es una fucnion en un espacio de frecuencias, lo que ayuda es a identificar frecuencias importantes, identificar el factor, cada tanto ocurre un factor ciclico o esatcional

Se ve medio picudo, como sucio. La linea indica la frecuencia que es importante, lo que acompaña el v en el abline, entonces es una frecuencia es importante, hay que entender en qué frecuencia estaban los datos, parece que la linea es un 1/16, es una cada vez diez años

 
4.15 Repita el problema 4.10 utilizando un procedimiento de estimación espectral no paramétrico. Además de discutir sus hallazgos en detalle, comente su elección de una estimación espectral con respecto al suavizado y la disminución gradual.
```{r}
data("saltemp")
par(mfrow=c(2,1))
mvspec(saltemp, taper=0)
abline(v=1/16, lty="dashed")
mvspec(saltemp, spans=c(7,7), log="no", taper=0.5)
abline(v=1/16, lty="dashed")
salt.per = mvspec(salt, spans=c(7,7), log="no", taper=.5)
abline(v=1/16, lty="dashed")#kernell("daniell",4)


mvspec(sunspotz, log = "no")
mvspec(sunspotz, spans = c(7,7), taper = 0.1, log = "no")
abline(v= 1/11, col="blue")


```
 
 Por problema 4.9 se tiene lo anterior, entonces se continua con 
 
```{r}
par(mfrow=c(2,1))
mvspec(saltemp, spans=c(7,7), log="no", taper=.5)
abline(v=1/16, lty="dashed")
salt.per = mvspec(salt, spans=c(7,7), log="no", taper=.5)
abline(v=1/16, lty="dashed")

```
 


