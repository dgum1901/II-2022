<<<<<<< HEAD
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
data(blocks); par(mfrow=c(2, 4))
m1 <- lm( Time~Shape, data=blocks); anova(m1)
### Part 1
plot( rstandard(m1) ~ fitted(m1) )
qqnorm( rstandard(m1) ); qqline( rstandard(m1) )
plot( cooks.distance(m1), type="h")
plot( rstandard(m1) ~ blocks$Shape)
rowSums(influence.measures(m1)$is.inf)
influence.measures(p)
#rowSums(influence.measures(p)$is.inf)
library("GLMsData")
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
newA
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
## Global options
knitr::opts_chunk$set(cache = TRUE)
library(readxl)
cauciones <- read_excel("cauciones.xlsx",
sheet = "Hoja 1")
View(cauciones)
450000*5
400000*5
500000*5
462200*5
2311000/12
2311000/24
2311000/36
2311000/39
2311000/41
2311000/43
2311000/45
2311000/46
2350000/51032
2250000/46.04954
2311000/51032
2250000/45.28531
462200/8
scatter.smooth( jitter(blocks$Number)~blocks$Age )
sd((blocks$Number))
var(blocks$Number)
mean(blocks$Number)
var(blocks$Number)-mean(blocks$Number)
blocks$Number
ppois(mean(blocks$Number), 1.8)
ppois(13, 1.8)
ppois(13, mean(blocks$Number))
ppois(100, mean(blocks$Number))
ppois(6, mean(blocks$Number))
ppois(max(blocks$Number), mean(blocks$Number))
1-ppois(max(blocks$Number), mean(blocks$Number))
ppois((blocks$Number), mean(blocks$Number))
mean(ppois((blocks$Number), mean(blocks$Number)))
var(blocks$Number)
mean(blocks$Number)
influence.measures(p)
rowSums(influence.measures(p)$is.inf)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
m1$null.deviance - m1$deviance
#1 - pchisq (64 .91309 , 1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
m1
View(m1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
m1
m0
confint(m1)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
qresid(m1)
cooks.distance(m1)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1o)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
which(rowSums(influence.measures(m1)$is.inf)>0)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
m2 <- glm(cbind(Females,Males)~Party + Region, data=base1,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
View(belection)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
library("GLMsData")
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
sd((blocks$Number))
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
confint(m1)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
influence.measures(m1)
which(rowSums(influence.measures(m1)$is.inf)>0)
deviance(m1)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
library("GLMsData")
=======
x <- Babies$PromedioTemperatura
y <- Babies$PromedioSemanas
lm.out <- lm(y ~ x)
newx = seq(min(x),max(x),by = 0.05)
conf_interval <- predict(lm.out, newdata=data.frame(x=newx), interval="confidence",
level = 0.95)
plot(x, y, xlab="x", ylab="y", main="Regression")
abline(lm.out, col="lightblue")
lines(newx, conf_interval[,2], col="blue", lty=2)
lines(newx, conf_interval[,3], col="blue", lty=2)
conf_interval
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
conf_interval[,2]
x=1:ncol(Babies)
x
1:nrow(Babies)
?predict
cosa <- predict(q, newdata=data.frame(x=1:nrow(Babies)), interval="confidence", level = 0.95)
x <- Babies$PromedioTemperatura
cosa <-
predict(q,
newdata = data.frame(x = seq(min(x), max(x), by = 0.05)),
interval = "confidence",
level = 0.95)
seq(min(x), max(x), by = 0.05)
q
lm.out
predict(lm.out, newdata=data.frame(x=newx), interval="confidence",
level = 0.95)
x <- Babies$PromedioTemperatura
x
seq(min(x), max(x), by = 0.05)
q
predict(q,
newdata = data.frame(x = seq(min(x), max(x), by = 0.05)),
interval = "confidence",
level = 0.95)
cosa <- data.frame(seq(min(x), max(x), by = 0.05))
View(cosa)
cosa <-
predict(q,
newdata = data.frame(x = cosa),
interval = "confidence",
level = 0.95)
x <- Babies$PromedioTemperatura
y <- Babies$PromedioSemanas
lm.out <- lm(y ~ x)
newx = seq(min(x),max(x),by = 0.05)
conf_interval <- predict(lm.out, newdata=data.frame(x=newx), interval="confidence",
level = 0.95)
plot(x, y, xlab="x", ylab="y", main="Regression")
abline(lm.out, col="lightblue")
lines(newx, conf_interval[,2], col="blue", lty=2)
lines(newx, conf_interval[,3], col="blue", lty=2)
cosa <- data.frame(x = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
x <- Babies$PromedioTemperatura
y <- Babies$PromedioSemanas
lm.out <- lm(y ~ x)
newx = seq(min(x),max(x),by = 0.05)
conf_interval <- predict(lm.out, newdata=data.frame(x=newx), interval="confidence",
level = 0.95)
plot(x, y, xlab="x", ylab="y", main="Regression")
abline(lm.out, col="lightblue")
lines(newx, conf_interval[,2], col="blue", lty=2)
lines(newx, conf_interval[,3], col="blue", lty=2)
conf_interval <- predict(q, newdata=data.frame(x=newx), interval="confidence",
level = 0.95)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
cosa <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
cosa <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, ylim = c(28,40),
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(newx, cosa[,2], col="blue", lty=2)
lines(newx, cosa[,3], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
cosa <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(newx, cosa[,2], col="blue", lty=2)
lines(newx, cosa[,3], col="blue", lty=2)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = x,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
data(flowers)
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
data(flowers)
library(GLMsData)
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
### Part 1
scatter.smooth( rstandard(m1) ~ fitted(m1) )
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
### Part 1
scatter.smooth( rstandard(m1) ~ fitted(m1) )
qqnorm( rstandard(m1) ); qqline( rstandard(m1) )
plot( cooks.distance(m1), type="h")
plot( rstandard(m1) ~ flowers$Light)
### Part 2
rowSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
?influence.measures
influence.measures(m1)$is.inf
rowSums(influence.measures(q)$is.inf)
influence.measures(q)$is.inf
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" )
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
<<<<<<< HEAD
sd((blocks$Number))
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
confint(m1)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
deviance(m1)
deviance(m3)
data(blocks)
library(statmod)
m3 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m3)~fitted(m3))
plot(cooks.distance(m3), type="h")
qqnorm(rstandard(m3))
qqnorm(qresid(m3))
colSums(influence.measures(m3)$is.inf)
influence.measures(m3)
which(rowSums(influence.measures(m3)$is.inf)>0)
deviance(m3)
deviance(m1)
summary(m1)
summary(m1)
df.residual(m1)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
deviance(m2)
summary(m2)
df.residual(m2)
df.residual(m3)
W <- weights(m2, type="working")
e <- residuals(m2, type="working")
# Estadístico de Pearson
sum( W * e^2 )
min(belection$Females)
belection$Females
min(belection$Females+ belection$Males )
min(belection$Males )
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(mod_leo,
=======
data(nminer) # Load the data
> names(nminer) # Show the variables
[1] "Miners" "Eucs" "Area" "Grazed" "Shrubs" "Bulokes" "Timber"
[8] "Minerab"
> plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
data(nminer) # Load the data
names(nminer) # Show the variables
data(nminer) # Load the data
names(nminer) # Show the variables
knitr::opts_chunk$set(echo = TRUE)
library("GLMsData")
data(blocks)
data(nminer)
data(nminer) # Load the data
names(nminer)
plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
knitr::opts_chunk$set(echo = TRUE)
plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
m1 <- glm(Number~Age, data=blocks, family=logistic)
m1 <- glm(Number~Age, data=blocks, family=binomial)
m1 <- glm(Number~Age, data=blocks, family=quasibinomial)
m1 <- glm(Number~Age, data=blocks, family=logit)
m1 <- glm(Number~Age, data=blocks, family=gaussian)
m1; deviance(m1); summary(m1)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m1; deviance(m1); summary(m1)
deviance(m1); summary(m1)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m1
deviance(m1); summary(m1)
coef(summary(m1))
cov.mat <- summary(m1)$cov.scaled
coef(summary(m1))
cov.mat <- summary(m1)$cov.scaled
sqrt( diag( cov.mat ) )
View(cov.mat)
#Pag 258
deviance(m1)
m0 <- update(m1, .~1)
m0
m0 <- update(m1, .~1)
m0
m1
?update
summary(m0)
summary(m1)
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
z.Wald <- coef(summary(m1))[2, 3]
P.Wald <- coef(summary(m1))[2, 4]
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
coef(summary(m1))
data(quiplie)
data(quiplie)
data(quiplie)
library(GLMsData)
data(quiplie)
data(quilpie)
m1.quilpie$coef
View(quilpie)
m1.quilpie <- lm(y ~ SOE, data = quilpie)
m1.quilpie <- lm(y ~ SOI, data = quilpie)
coef(m1.quilpie)
m1.quilpie$coefficients
m1.quilpie <- lm(y ~ ., data = quilpie)
coef(m1.quilpie)
m1.quilpie$coefficients
m1.quilpie <- lm(y ~ SOI, data = quilpie)
coef(m1.quilpie)
m1.quilpie <- lm(y ~ Phase, data = quilpie)
coef(m1.quilpie)
coef(summary(m1))
library(aod)
library(aod)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1))
coef(m1)
vcov(m1)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 3:4)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 1)
coef(summary(m1))
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
summary(m1)
coef(summary(m1))
var(blocks$Number)
mean(blocks$Number)
ppois( 7, 1.8)
ppois( 7, 2.5)
ppois( 7, 1.8)
ppois( 7, 2.5)
ppois(q=12, lambda=30)
ppois(12,30)
var(blocks$Number)
mean(blocks$Number)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
<<<<<<< HEAD
=======
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
rowSums(influence.measures(q)$is.inf)
rowSums(influence.measures(p)$is.inf)
beta <- c(0.23, 0.04, 0.06, 0.01, 0.09, 0.05, 0.30)
se <- c(0.13, 0.04, 0.05, 0.03, 0.06, 0.02, 0.07)
z <- beta/se; pvals <- (1-pnorm(abs(z)))*2
round(pvals, 3)
z
0.1415096/0.05340039
summary(m1)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
library(statmod)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
library(statmod)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(p), b = coef(p), Terms = 1) #se rechaza la hipotesis nula
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 1) #se rechaza la hipotesis nula
?glm.scoretest
update(m1, .~1)
m1
m0
m1
library(statmod)
#Toma el modelo vacío m0 y
( z.score <- glm.scoretest(m0, blocks$Age) )
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1))) )
(2 * pnorm( abs(z.score), lower.tail=FALSE))
chisq.LRT <- anova(m1)[2, 2]
P.LRT <- anova(m1, test="Chisq")[2, 5]
library(statmod)
#Toma el modelo vacío m0 y
( z.score <- glm.scoretest(m0, blocks$Age) )
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1))) )
chisq.LRT <- anova(m1)[2, 2]
P.LRT <- anova(m1, test="Chisq")[2, 5]
(chisq.LRT <- anova(m1)[2, 2])
(P.LRT <- anova(m1, test="Chisq")[2, 5])
anova(m1)
anova(m1)
?anova
anova(m1, test="Chisq")
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
analisis
analisis[2,2]
analisis[2, 5]
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
(chisq.LRT <- analisis[2,2])
(P.LRT <- analisis[2, 5])
round(c(z.Wald, z.score, sqrt(chisq.LRT)), 4)
round(c(P.Wald, P.score, P.LRT), 4); min(blocks$Number)
round(c(z.Wald, z.score, sqrt(chisq.LRT)), 4)
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
View(q)
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
