level = 0.95)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
cosa <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, ylim = c(28,40),
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(newx, cosa[,2], col="blue", lty=2)
lines(newx, cosa[,3], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
cosa <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = cosa,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(newx, cosa[,2], col="blue", lty=2)
lines(newx, cosa[,3], col="blue", lty=2)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-
data.frame(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = x,
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" , conf = cosa)
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
data(flowers)
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
data(flowers)
library(GLMsData)
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
### Part 1
scatter.smooth( rstandard(m1) ~ fitted(m1) )
data(flowers)
m1 <- lm(Flowers~Light+Timing, data=flowers)
### Part 1
scatter.smooth( rstandard(m1) ~ fitted(m1) )
qqnorm( rstandard(m1) ); qqline( rstandard(m1) )
plot( cooks.distance(m1), type="h")
plot( rstandard(m1) ~ flowers$Light)
### Part 2
rowSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
?influence.measures
influence.measures(m1)$is.inf
rowSums(influence.measures(q)$is.inf)
influence.measures(q)$is.inf
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" )
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
<<<<<<< HEAD
sd((blocks$Number))
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
confint(m1)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
deviance(m1)
deviance(m3)
data(blocks)
library(statmod)
m3 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m3)~fitted(m3))
plot(cooks.distance(m3), type="h")
qqnorm(rstandard(m3))
qqnorm(qresid(m3))
colSums(influence.measures(m3)$is.inf)
influence.measures(m3)
which(rowSums(influence.measures(m3)$is.inf)>0)
deviance(m3)
deviance(m1)
summary(m1)
summary(m1)
df.residual(m1)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
deviance(m2)
summary(m2)
df.residual(m2)
df.residual(m3)
W <- weights(m2, type="working")
e <- residuals(m2, type="working")
# Estadístico de Pearson
sum( W * e^2 )
min(belection$Females)
belection$Females
min(belection$Females+ belection$Males )
min(belection$Males )
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(mod_leo,
=======
data(nminer) # Load the data
> names(nminer) # Show the variables
[1] "Miners" "Eucs" "Area" "Grazed" "Shrubs" "Bulokes" "Timber"
[8] "Minerab"
> plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
data(nminer) # Load the data
names(nminer) # Show the variables
data(nminer) # Load the data
names(nminer) # Show the variables
knitr::opts_chunk$set(echo = TRUE)
library("GLMsData")
data(blocks)
data(nminer)
data(nminer) # Load the data
names(nminer)
plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
knitr::opts_chunk$set(echo = TRUE)
plot( jitter(Minerab) ~ Eucs, data=nminer, las=1, ylim=c(0, 20),
xlab="Number of eucalypts per 2 ha", ylab="Number of noisy miners" )
m1 <- glm(Number~Age, data=blocks, family=logistic)
m1 <- glm(Number~Age, data=blocks, family=binomial)
m1 <- glm(Number~Age, data=blocks, family=quasibinomial)
m1 <- glm(Number~Age, data=blocks, family=logit)
m1 <- glm(Number~Age, data=blocks, family=gaussian)
m1; deviance(m1); summary(m1)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m1; deviance(m1); summary(m1)
deviance(m1); summary(m1)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m1
deviance(m1); summary(m1)
coef(summary(m1))
cov.mat <- summary(m1)$cov.scaled
coef(summary(m1))
cov.mat <- summary(m1)$cov.scaled
sqrt( diag( cov.mat ) )
View(cov.mat)
#Pag 258
deviance(m1)
m0 <- update(m1, .~1)
m0
m0 <- update(m1, .~1)
m0
m1
?update
summary(m0)
summary(m1)
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
z.Wald <- coef(summary(m1))[2, 3]
P.Wald <- coef(summary(m1))[2, 4]
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
coef(summary(m1))
data(quiplie)
data(quiplie)
data(quiplie)
library(GLMsData)
data(quiplie)
data(quilpie)
m1.quilpie$coef
View(quilpie)
m1.quilpie <- lm(y ~ SOE, data = quilpie)
m1.quilpie <- lm(y ~ SOI, data = quilpie)
coef(m1.quilpie)
m1.quilpie$coefficients
m1.quilpie <- lm(y ~ ., data = quilpie)
coef(m1.quilpie)
m1.quilpie$coefficients
m1.quilpie <- lm(y ~ SOI, data = quilpie)
coef(m1.quilpie)
m1.quilpie <- lm(y ~ Phase, data = quilpie)
coef(m1.quilpie)
coef(summary(m1))
library(aod)
library(aod)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1))
coef(m1)
vcov(m1)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 3:4)
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 1)
coef(summary(m1))
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
summary(m1)
coef(summary(m1))
var(blocks$Number)
mean(blocks$Number)
ppois( 7, 1.8)
ppois( 7, 2.5)
ppois( 7, 1.8)
ppois( 7, 2.5)
ppois(q=12, lambda=30)
ppois(12,30)
var(blocks$Number)
mean(blocks$Number)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
<<<<<<< HEAD
=======
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
colnames(Babies) <- c('Mes','PromedioSemanas','TamMuestra','PromedioTemperatura')
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
q <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = TamMuestra)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
summary(q)
confint(q, level = 0.9)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab = "Promedio Temperatura", ylab = "Promedio semanas" )
abline(coef(p), lty = 1, lwd = 2)
abline(coef(q), lty = 2, lwd = 2)
cosa <- confint(q)
x <- Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
scatter.smooth(rstandard(q) ~ fitted(q))
qqnorm(rstandard(q))
qqline(rstandard(q))
plot(cooks.distance(q), type = "h")
plot(rstandard(q) ~ Babies$PromedioTemperatura)
rowSums(influence.measures(q)$is.inf)
rowSums(influence.measures(p)$is.inf)
beta <- c(0.23, 0.04, 0.06, 0.01, 0.09, 0.05, 0.30)
se <- c(0.13, 0.04, 0.05, 0.03, 0.06, 0.02, 0.07)
z <- beta/se; pvals <- (1-pnorm(abs(z)))*2
round(pvals, 3)
z
0.1415096/0.05340039
summary(m1)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
library(statmod)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
library(statmod)
#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado:
( z.score <- glm.scoretest(m0, blocks$Age))
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(p), b = coef(p), Terms = 1) #se rechaza la hipotesis nula
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
#Esto borra la edad como variable del modelo :0
m0 <- update(m1, .~1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
#perform Wald Test to determine if 3rd and 4th predictor variables are both zero
wald.test(Sigma = vcov(m1), b = coef(m1), Terms = 1) #se rechaza la hipotesis nula
?glm.scoretest
update(m1, .~1)
m1
m0
m1
library(statmod)
#Toma el modelo vacío m0 y
( z.score <- glm.scoretest(m0, blocks$Age) )
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1))) )
(2 * pnorm( abs(z.score), lower.tail=FALSE))
chisq.LRT <- anova(m1)[2, 2]
P.LRT <- anova(m1, test="Chisq")[2, 5]
library(statmod)
#Toma el modelo vacío m0 y
( z.score <- glm.scoretest(m0, blocks$Age) )
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1))) )
chisq.LRT <- anova(m1)[2, 2]
P.LRT <- anova(m1, test="Chisq")[2, 5]
(chisq.LRT <- anova(m1)[2, 2])
(P.LRT <- anova(m1, test="Chisq")[2, 5])
anova(m1)
anova(m1)
?anova
anova(m1, test="Chisq")
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
analisis
analisis[2,2]
analisis[2, 5]
analisis <- anova(m1, test="Chisq") #analysis of variance (or deviance)
(chisq.LRT <- analisis[2,2])
(P.LRT <- analisis[2, 5])
round(c(z.Wald, z.score, sqrt(chisq.LRT)), 4)
round(c(P.Wald, P.score, P.LRT), 4); min(blocks$Number)
round(c(z.Wald, z.score, sqrt(chisq.LRT)), 4)
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
View(q)
>>>>>>> 8a1a8bf2e943b7c9c7f25de55c1ea75272e8898b
knitr::opts_chunk$set(echo = TRUE)
influence.measures(mod_leo)
influence.measures(mod_leo)$is.inf
