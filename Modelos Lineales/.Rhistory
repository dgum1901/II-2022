Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
data(blocks); par(mfrow=c(2, 4))
m1 <- lm( Time~Shape, data=blocks); anova(m1)
### Part 1
plot( rstandard(m1) ~ fitted(m1) )
qqnorm( rstandard(m1) ); qqline( rstandard(m1) )
plot( cooks.distance(m1), type="h")
plot( rstandard(m1) ~ blocks$Shape)
rowSums(influence.measures(m1)$is.inf)
influence.measures(p)
#rowSums(influence.measures(p)$is.inf)
library("GLMsData")
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
newA
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
## Global options
knitr::opts_chunk$set(cache = TRUE)
library(readxl)
cauciones <- read_excel("cauciones.xlsx",
sheet = "Hoja 1")
View(cauciones)
450000*5
400000*5
500000*5
462200*5
2311000/12
2311000/24
2311000/36
2311000/39
2311000/41
2311000/43
2311000/45
2311000/46
2350000/51032
2250000/46.04954
2311000/51032
2250000/45.28531
462200/8
scatter.smooth( jitter(blocks$Number)~blocks$Age )
sd((blocks$Number))
var(blocks$Number)
mean(blocks$Number)
var(blocks$Number)-mean(blocks$Number)
blocks$Number
ppois(mean(blocks$Number), 1.8)
ppois(13, 1.8)
ppois(13, mean(blocks$Number))
ppois(100, mean(blocks$Number))
ppois(6, mean(blocks$Number))
ppois(max(blocks$Number), mean(blocks$Number))
1-ppois(max(blocks$Number), mean(blocks$Number))
ppois((blocks$Number), mean(blocks$Number))
mean(ppois((blocks$Number), mean(blocks$Number)))
var(blocks$Number)
mean(blocks$Number)
influence.measures(p)
rowSums(influence.measures(p)$is.inf)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
m1$null.deviance - m1$deviance
#1 - pchisq (64 .91309 , 1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
m1
View(m1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
m1
m0
confint(m1)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
qresid(m1)
cooks.distance(m1)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1o)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
influence.measures(m1)
rowSums(influence.measures(m1)$is.inf)
which(rowSums(influence.measures(m1)$is.inf)>0)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
m2 <- glm(cbind(Females,Males)~Party + Region, data=base1,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
View(belection)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
library("GLMsData")
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
sd((blocks$Number))
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
confint(m1)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
data(blocks)
library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m1)~fitted(m1))
plot(cooks.distance(m1), type="h")
qqnorm(rstandard(m1))
qqnorm(qresid(m1))
colSums(influence.measures(m1)$is.inf)
influence.measures(m1)
which(rowSums(influence.measures(m1)$is.inf)>0)
deviance(m1)
knitr::opts_chunk$set(echo = TRUE)
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
library(GLMsData)
#Babies<-data(crawl)
colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)
p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)
coef(mod_leo)
summary(mod_leo)
confint(mod_leo, level = 0.9)
mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)
coef(mod_leo)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(q,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
confint(mod_leo, level = 0.95)
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
#
#
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
qqnorm( rstandard(mod_leo) )
qqline( rstandard(mod_leo) )
plot( cooks.distance(mod_leo), type="h")
plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
library("GLMsData")
data(blocks)
#par(mfrow=c(1, 2))
#plot(jitter(Number)~Age, data=blocks)
#plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
var(blocks$Number)
mean(blocks$Number)
sd((blocks$Number))
data(blocks)
m1 <- glm(Number~Age, data=blocks, family=poisson)
deviance(m1)
summary(m1)
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)
data(blocks); library(statmod)
m1 <- glm(Number~Age, data=blocks, family=poisson)
m0 <- update(m1, .~1)
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
(P.Wald <- coef(summary(m1))[2, 4])
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
c(z.Wald, z.score, sqrt(chisq.LRT))
round(c(P.Wald, P.score, P.LRT), 4)
min(blocks$Number)
confint(m1)
newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
lines(newB$fit ~ newA, lwd=2)
t.star <- qt(p=0.975, df=df.residual(m1))
ci.lo <- newB$fit - t.star * newB$se.fit
ci.hi <- newB$fit + t.star * newB$se.fit
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
deviance(m1)
deviance(m3)
data(blocks)
library(statmod)
m3 <- glm(Number~Age, data=blocks, family=poisson)
par(mfrow=c(2, 2))
plot( rstandard(m3)~fitted(m3))
plot(cooks.distance(m3), type="h")
qqnorm(rstandard(m3))
qqnorm(qresid(m3))
colSums(influence.measures(m3)$is.inf)
influence.measures(m3)
which(rowSums(influence.measures(m3)$is.inf)>0)
deviance(m3)
deviance(m1)
summary(m1)
summary(m1)
df.residual(m1)
m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial())
par(mfrow=c(2, 2))
plot( rstandard(m2)~fitted(m2))
plot(cooks.distance(m2), type="h")
qqnorm(rstandard(m2))
qqnorm(qresid(m2))
colSums(influence.measures(m2)$is.inf)
influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
deviance(m2)
summary(m2)
df.residual(m2)
df.residual(m3)
W <- weights(m2, type="working")
e <- residuals(m2, type="working")
# Estadístico de Pearson
sum( W * e^2 )
min(belection$Females)
belection$Females
min(belection$Females+ belection$Males )
min(belection$Males )
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
predict(mod_leo,
newdata = data.frame(x),
interval = "confidence",
level = 0.95)
plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(q), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
