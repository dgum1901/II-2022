---
title: "Ejer"
author: "Maria Jose Corea"
date: "2022-10-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

2.16 Un estudio de bebés planteó la hipótesis de que los bebés tardarían más en
aprender a gatear en los meses más fríos porque la ropa extra restringe su
movimiento. Entre 1988 y 1991, la primera edad de gateo de los bebés y el promedio
se registró la temperatura mensual seis meses después del nacimiento (cuando “los bebés presumiblemente entran en la ventana de preparación locomotora”; p. 72). Los padres
informaron el mes de nacimiento y la edad en que su bebé se arrastró o gateó por primera vez
distancia de cuatro pies en un minuto. Los datos fueron recolectados en la Universidad de
Denver Infant Study Center sobre 208 niños y 206 niñas, y resumido por
el mes de nacimiento (Tabla 2.10; conjunto de datos: rastreo).
1. Trazar los datos. ¿Qué suposiciones, si las hubiere, parecen violarse?
2. Explique por qué un modelo de regresión ponderado es apropiado para los datos.
3. Ajuste un modelo de regresión lineal ponderado a los datos e interprete el
coeficientes de regresión.
4. Probar formalmente la hipótesis propuesta por los investigadores.
5. Encuentre un intervalo de confianza del 90 % para la pendiente de la línea ajustada, y
interpretar.
6. Ajuste el modelo de regresión no ponderado, luego trace ambas líneas de regresión en
una trama de los datos. Comenta las diferencias.
7. Calcule los intervalos de confianza del 95 % para los valores ajustados de la
línea de regresión ponderada, y también grafíquelos.
8. Interpreta el modelo.


```{r}
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
 library(GLMsData)
#Babies<-data(crawl)

colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')


```

1.R\

```{r}
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)


p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)

plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
```
Al realizar la comparación del promedio de semanas hasta gatear y el rpomedio de la temperatura en los siguientes 6 meses, se puede observar una relativa linealidad decreciente, es decir, que en cuanto más frío esté, menos son los reportes de que los niños gateen. Y se encuentra un outlyer entre 50 y 60.

2.R\

Porque la regresión ponderada se puede utilizar para corregir la heterocedasticidad. En un procedimiento de regresión ponderada, se otorga más peso a las observaciones con una varianza más pequeña porque estas observaciones brindan información más confiable sobre la función de regresión que aquellas con varianzas grandes. Observemos que la varianza de las observaciones, asimismo la desviación estándar y un histograma para ver si se ve normalidad.

Como son promedios y deben considerarse que los promedio son toamdos de disntintas poblaciones.

```{r}
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
```
3.R/

```{r}

mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)

coef(mod_leo)
```
Un aumento en una unidad de temperatura, que es unica covariable y provoca una disminucuion de mas 0.75 en promedio en la edad promedio de gateo, amnteniendo las demás variables constante. Un unidad de la tempratura sube, indica que el promedio de la edad promedio baja en o.075, nomina lmente, funcio de enlacio que es la identidad.
Un aumento de la temperatura proboca una disminucion de apro de 0.075 en promedio de la edad promedio,  como estamps viedno la esperanza, que estamos viendo mu, que es la esperanza de Y.

Es importante ver que al menos sale negativo el coeficiente, que es lo que espera el estudio,puesto que tienen una relación negativa.

4. R/

```{r}
summary(mod_leo)
```


Nos salio una prueba de t, con un nivel de 5% de confianza, si se rechaza y con un 1% de significancia, no se rechaza.


5.R/

El IC95% aporta al lector la precisión estadística. Por «precisión estadística», se refiere a la incertidumbre introducida por los métodos de muestreo. Es un intervalo bastante pequeño, lo cual sin ser muy conservadores, se encuentra el rango de error. Esto es que el 90% de las veces, casi seguramente, el coeficiente de la varaible se va a encontrar en ese intervalo.

```{r}
confint(mod_leo, level = 0.9)

```

6.R/

```{r}

mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)

coef(mod_leo)

```

Un aumento en una unidad de temperatura, que es unica covariable y provoca una disminucuion de mas 0.75 en promedio en la edad promedio de gateo, amnteniendo las demás variables constante. Un unidad de la tempratura sube, indica que el promedio de la edad promedio baja en 0.077, nomina lmente, funcio de enlacio que es la identidad.
Un aumento de la temperatura proboca una disminucion de apro de 0.077 en promedio de la edad promedio,  como estamps viedno la esperanza, que estamos viendo mu, que es la esperanza de Y.

Es importante ver que al menos sale negativo el coeficiente, que es lo que espera el estudio,puesto que tienen una relación negativa.

Entonces baja un 0.002, o sea el impacto es mayor.

```{r}

plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
```

Asimismo, se puede ver mediante el gráfico una diferencia no tan abismal.

7.R/

```{r}
x<-Babies$PromedioTemperatura
x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
cosa <-
  predict(mod_leo,
          newdata = data.frame(x),
          interval = "confidence",
          level = 0.95)


plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
      xlab = "Promedio Temperatura", ylab = "Promedio semanas")
abline(coef(mod_leo), lty = 1, lwd = 2)
lines(x, cosa[,2], col="blue", lty=2)
lines(x, cosa[,3], col="blue", lty=2)
```


```{r}
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
```

No reduce muy significativamente el intervalo de confianza, siendo un 5% más conservadores, esto probablemente por la variabilidad de las observaciones
```{r}
confint(mod_leo, level = 0.95)

```
```{r}
#x <- Babies$PromedioTemperatura
#x <-(PromedioTemperatura = seq(min(x), max(x), by = 0.05))
#cosa <-
#   predict(q,
#           newdata = data.frame(x),
#           interval = "confidence",
#           level = 0.95)
# 
# 
# plot( PromedioSemanas ~ PromedioTemperatura, data=Babies,
#       xlab = "Promedio Temperatura", ylab = "Promedio semanas")
# abline(coef(q), lty = 1, lwd = 2)
# lines(x, cosa[,2], col="blue", lty=2)
# lines(x, cosa[,3], col="blue", lty=2)
```


8.R/

Como rompe con el supuesto de variabilidad nula, entonces se necesita un ajuste mediante los pesos, el cual no mejora significativamente la regresión, lo importante es notar es que si se logra la relación inversa con lo propuesto mediante la hip nula.


3.15. Un estudio de bebés [4] planteó la hipótesis de que los bebés tardarían más en
aprender a gatear en los meses más fríos porque la ropa extra restringe su
movimiento (conjunto de datos: rastreo). Los datos y una descripción más completa se dan en
Problema 2.16 (pág. 87). En ese problema, se ajustó un modelo de regresión lineal
a los datos
1. Realice un análisis de diagnóstico del modelo de regresión lineal ajustado.
2. Identifique las observaciones influyentes o los valores atípicos.
3. Suponga que algunos de los bebés fueran mellizos. ¿Qué suposición sería
violado por la inclusión de estos bebés en el estudio? ¿Crees que esto
tendría implicaciones prácticas

1.R/
```{r}
rstandard(mod_leo)#residual estandarizado
fitted(mod_leo) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(mod_leo) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
 scatter.smooth( rstandard(mod_leo) ~ fitted(mod_leo) )
 qqnorm( rstandard(mod_leo) )
 qqline( rstandard(mod_leo) )
 plot( cooks.distance(mod_leo), type="h")
 plot( rstandard(mod_leo) ~ Babies$PromedioTemperatura)
 
```

2.R/

```{r}
influence.measures(mod_leo)
rowSums(influence.measures(mod_leo)$is.inf)
```
 
 Hay una tendencia lineal, hay presencia de 3 outliers, el de la posición 2, 3 y 5, o se en febrero, marzo y mayo. Son de influencia.
 
3.R/

ausencia de outliers todas las fespuestas fiueron generadas por el mismo proceso, de manera que el modelo de regresion es aporpiado para todas las observaciones. Si hay outliers que sean obtenidos por el mismo proceso de recopilacion de datos
linealidad: El predictor lineal captura la evrdadera relacion enrre mu_i y las variables explicatoroas, todas las variavles explicatorias importantes se incluyen
varianza constante: la variable respiesta yi tiene varianza constante, demás de pesos conocidos como wi
independencia: Def de independiente 
distribución: LA variable respuesta está normalmente distribuida al rededor de su media mui

R/Si hay gemelos, se rompe la de independencia.
 
5.25. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [2, 9]. El número de bloques utilizados y el tiempo empleado
fueron registrados (Tabla 2.12; conjunto de datos: bloques). En este problema, sólo considere
el número de bloques utilizados y y la edad del niño x.

1. Grafique el número de bloques usados contra la edad del niño.

2. A partir de la gráfica y la comprensión de los datos, responda las dos preguntas para estos datos y, por lo tanto, proponga un glm para los datos.

1.R/

```{r}
library("GLMsData") 
data(blocks)

 #par(mfrow=c(1, 2))
 #plot(jitter(Number)~Age, data=blocks)
 #plot( Number~cut(Age, 3), data=blocks)
plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" ) #el jitter agrega un poco de ruido, para que se traslap
```
1. ¿Qué distribución de probabilidad es apropiada? La respuesta determina la
componente aleatoria del modelo. La elección de la distribución de probabilidad
pueden ser sugeridos por los datos de respuesta (por ejemplo, proporciones de un
total sugieren una distribución binomial), o el conocimiento de cómo la varianza
cambia con la media.

```{r}
var(blocks$Number)
mean(blocks$Number)
sd((blocks$Number))
```
La varianza es menor a la esperanza(media), es una distribución poisson

2. ¿Cómo se relacionan las variables explicativas con la media de la respuesta?
¿? La respuesta sugiere el componente sistemático del modelo. glms
asumir una función que une el predictor lineal η = β0 + p
j=1 βjxj a
la media μ, como log μ = η por ejemplo. Es decir, glms son regresión
modelos lineales en los parámetros.

se relaciona de una manera similar

6.10. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [3, 6]. El número de bloques utilizados y el tiempo empleado
fueron registrados (conjunto de datos: bloques). En este problema, sólo considere el número
de bloques utilizados y y la edad del niño x. En el Problema 5.25, un glm fue
propuesta para estos datos.
1. Ajuste este glm usando r y escriba el modelo ajustado.
2. Determinar el error estándar para cada parámetro de regresión.
3. Calcule la desviación residual.

1.R/

```{r}
data(blocks)
 m1 <- glm(Number~Age, data=blocks, family=poisson)

```
2.R/

```{r}

deviance(m1)
```


3.R/

```{r}
summary(m1)
```
```{r}
m1$null.deviance - m1$deviance
1 - pchisq (7.185388, 1)

```
Se puede rechazar claramente la hipótesis nula. Hay una relación significativa con la edad.



7.4. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [3, 7]. El número de bloques utilizados y el tiempo empleado
fueron registrados (conjunto de datos: bloques). En este problema, sólo considere el número
de bloques utilizados y y la edad del niño x. En el problema 6.10, se ajustó un glm
para estos datos.
1. Use una prueba de Wald para determinar si la edad parece necesaria en el modelo.
2. Use una prueba de puntuación para determinar si la edad parece necesaria en el modelo.
3. Usar una prueba de razón de verosimilitud para determinar si la edad parece necesaria en el
modelo.
4. Compare los resultados de las pruebas de Wald, puntuación y razón de verosimilitud. comentario.
5. ¿Se espera que la aproximación del punto de silla sea precisa? Explique.
6. ¿Se espera que el teorema del límite central sea exacto? Explique.
7. Halle los intervalos de confianza de Wald al 95 % para los coeficientes de regresión.
8. Grafique el número de bloques usados contra la edad y muestre la relación
descrito por el modelo ajustado. Traza también las rectas que indican el debajo y
sobre al 95% de IC para estos valores ajustados.

```{r}
data(blocks); library(statmod)
 m1 <- glm(Number~Age, data=blocks, family=poisson)
 m0 <- update(m1, .~1)
 
```

1.R/
```{r}
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
 (P.Wald <- coef(summary(m1))[2, 4])
```
La edad tiene una significancia de 0.001, estonces sí es necesaria

2.R/

```{r}
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).

```
Pues con este modelo, se de muestras que es de significancia la edad

3.R/

```{r}
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
```
También se demuestra con un 0.001 la significancia de la edad con la verosimilitud
4.R/
```{r}
 c(z.Wald, z.score, sqrt(chisq.LRT))
 round(c(P.Wald, P.score, P.LRT), 4)
 
 
```
Se puede observar que con la prueba de likehood, pues la significancia de la edad es la más cercana a 0, o sea la que más ve relevante la edad

5.R/ Para un glm de Poisson, se espera que la aproximación del punto de silla sea suficiente si el
menor y ≥ 3; aquí el mínimo es 3, así que se espera que la aproximación del punto de silla esté bien. 
```{r}
min(blocks$Number)
```

6.R/Para un glm de Poisson, se espera que la aproximación teorema del limite central sea suficiente si es y ≥ 5; aquí el mínimo es 3, por lo que la aproximación teorema del limite central 
puede ser insuficientemente preciso.

7.R/

```{r}
confint(m1)
```


8.R/
```{r}
 newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
 newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
 lines(newB$fit ~ newA, lwd=2)
 t.star <- qt(p=0.975, df=df.residual(m1))
 ci.lo <- newB$fit - t.star * newB$se.fit
 ci.hi <- newB$fit + t.star * newB$se.fit
 lines(ci.lo~newA, lty=2)
 lines(ci.hi~newA, lty=2)
```

8.11. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [8, 14]. El número de bloques utilizados y el tiempo empleado
fueron registrados (conjunto de datos: bloques). En este problema, sólo considere el número
de bloques utilizados y y la edad del niño x.
En el problema 6.10, se ajustó un glm para estos datos. Realizar un diagnóstico
análisis y determinar si el modelo es adecuado


```{r}
 data(blocks)
library(statmod)
 m3 <- glm(Number~Age, data=blocks, family=poisson)
 par(mfrow=c(2, 2))
 plot( rstandard(m3)~fitted(m3))
 plot(cooks.distance(m3), type="h")
 qqnorm(rstandard(m3))
 qqnorm(qresid(m3))
 colSums(influence.measures(m3)$is.inf)
 
 influence.measures(m3)
which(rowSums(influence.measures(m3)$is.inf)>0)


deviance(m3)
df.residual(m3)

```
Hay una tendencia lineal. Hay alta influencia en las observaciones 10 22 44 69 72 94 95, no s eve una alta variabilidad. Está mal ajustado, puesto que su devianza es muy alta

9.10. El periódico Independent tabuló el género de todos los candidatos que se postularon para las elecciones generales británicas de 1992 (Tabla 9.10; conjunto de datos:
reflexión) [6].
1. Grafique la proporción de candidatas contra el Partido y comente.
2. Trazar la proporción de candidatas contra la Región y comentar.
3. Encontrar un glm binomial adecuado, asegurando un análisis de diagnóstico.
4. ¿Es evidente la sobredispersión? #la varianza, es menos de lo que realmente, usted estaría subestimando la longitud de los intervalos de confianza, subdispersion, usted daría un intervalo muy grande, en vez de hacerlo más estrecho. La varianza es mayor con la sobredispersion, entonces la prueba wald podría decir que variables son más significante que no lo son.
5. Interpretar el modelo ajustado.
6. Estimar e interpretar las probabilidades de que una candidata se postule para el
Partidos conservador y laborista. Luego calcule la razón de probabilidades de la
El partido conservador presenta a una candidata para las probabilidades del Laborismo
partido que presenta a una candidata.
7. Determine si es probable que la aproximación del punto de silla sea adecuada para
estos datos.

1.R/

```{r}
data(belection)
plot(belection$Females~belection$Party)
```
2.R/

```{r}
plot(belection$Females~belection$Region)
```

3.R/

```{r}
# library(dplyr)
# base1 <- belection%>%mutate(Party  = case_when( Party == 'Cons' ~ 0,
#                                                  Party == 'Green' ~ 1,
#                                                  Party == 'Labour' ~ 2,
#                                                  Party == 'LibDem' ~ 3,
#                                                  Party == 'Other' ~ 4))
```


```{r}
 m2 <- glm(cbind(Females,Males)~Party + Region, data=belection,    family=binomial()) #éxitos son mujeres y fracasos hombres
 par(mfrow=c(2, 2))
 plot( rstandard(m2)~fitted(m2))
 plot(cooks.distance(m2), type="h")
 qqnorm(rstandard(m2))
 qqnorm(qresid(m2))
 colSums(influence.measures(m2)$is.inf)
 
  influence.measures(m2)
which(rowSums(influence.measures(m2)$is.inf)>0)
deviance(m2)
summary(m2)
df.residual(m2)
min(belection$Females)
min(belection$Males)
```
 
```{r}
W <- weights(m2, type="working")
e <- residuals(m2, type="working")
# Estadístico de Pearson
sum( W * e^2 )

```
 
 
Hay alta influencien en las observaciones 12 16 18 20 23 25 34 36 45 51, se ve una baja variabilidad. Se presencia de linealidad. Se ve una dispersión, son bastante parecidos.

5.R/
Es importante decir que con el summary, se puede observar la significancia del partido sobre la región, entonces solo nos fijaremos con los odds de los partidos.

```{r}
printCoefmat(exp(coef(summary(m2))),digits=4)
```
Los odds son la razón de la prob de exito, entre la prob de fracaso. la prob de exito es 4 veces que la prob de fracaso.
En este caso como la variable es categórita, entonces se ve como, no se ve el cons, entonces ese el base, el 3.16 que acompaña al partido verda, esa es la expo del beta del partido verde 3.16 veces del partido de cons, entonces son 3.16 veces mayor que los del partido conservador. Por otro lado, los odds del democrático de 2. algo del cons

Que pasa si solo queiro los odds del partido verde?

eso se hace distinto

```{r}
exp(sum(coef(summary(m2))[1:2]))
```
La proporción de las mujeres es apenas 30% de la de los hombres en el partido verde

6.R/

```{r}
exp(coef(summary(m2))[1])*exp(coef(summary(m2))[3])

```
Entonces la proporción de las mujeres es 29% de la de los hombre en el partido laboyer

7.R/

No se cumple el punto de silla, puesto que 
```{r}
min(belection$Females)
```

Por lo tanto no se cumple.


9.14. En el Ejemplo 9.4, se introdujeron datos [3] con respecto a la germinación
de semillas, utilizando dos tipos de semillas y dos tipos de portainjertos (Cuadro 9.3).
Una forma alternativa de ingresar los datos es registrar si cada
semilla individual germina o no (conjunto de datos: germBin).
1. Ajuste el modelo equivalente al ajustado en el ejemplo 9.4, pero usando datos
preparado como en el archivo de datos germBin. Este modelo se basa en el uso de un Distribución de Bernoulli.
2. Muestre que tanto el glms de Bernoulli como el binomial producen los mismos valores
para las estimaciones de parámetros y errores estándar.
3. Muestre que los dos modelos producen diferentes valores para la desviación residual, pero los mismos valores para la desviación.
4. Muestre que los dos modelos producen resultados similares a partir de la secuencia
pruebas de razón de verosimilitud.
5. Compare las log-verosimilitudes de las distribuciones binomial y de Bernoulli.
Comentario.
6. Explique por qué no se puede detectar la sobredispersión en el modelo de Bernoulli.

1.R/


```{r}
library(forcats)
data(germ)
data(germBin)
# fct_rev invierte los niveles
m4 <- glm(fct_rev(Result) ~ Seeds + Extract , data=germBin,family = binomial())

m5  <- glm(Germ/Total ~ Seeds + Extract, family=binomial,
data=germ, weights=Total)

summary(m5)
summary(m4)
```

2.R/

```{r}
summary(m5)
summary(m4)
```

3.R/

```{r}
deviance(m4)
deviance(m5)

1 - pchisq (m4$null.deviance - m4$deviance, 1)
1 - pchisq (m5$null.deviance - m5$deviance, 1)
```

4.R/

```{r}
anova(m4)
anova(m4, test="Chisq")
(chisq.LRT <- anova(m4)[2, 2])
( P.LRT <- anova(m4, test="Chisq")[2, 5])
```
```{r}
anova(m5)
anova(m5, test="Chisq")

```
El modelo binomial es mejor que la bernoulli
```{r}
prod( dbinom(x = as.numeric(fct_rev(germBin$Result))-1, size = 1, prob=m4$fitted.values))
```
```{r}
prod(dbinom(x = germ$Germ, size = germ$Total, prob=m5$fitted.values))
```
Es mejor el modelo binomial, puesto que el valor de su producto de masa es mayor en la binomial que en la bernoulli

5.R/
```{r}
log(prod( dbinom(x = as.numeric(fct_rev(germBin$Result))-1, size = 1, prob=m4$fitted.values)))
```


```{r}
log(prod(dbinom(x = germ$Germ, size = germ$Total, prob=m5$fitted.values)))
```
Con la log verosimilitud, se ve que es mejor el modelo binomial, puesto que tiene el valor más cercano a 0.

6.R/

Es por la definición de devarianza residual, no tienen las mismas propiedades a que cuando tiene los datos agrupados o desagregados.Asimismo, no se puede punto de silla con pearson puesto que los datos son 0 y 1.

10.11. El número de muertes para 1969–1973 (1969–1972 para Bélgica) debido a el cáncer de cuello uterino se tabula (Cuadro 10.14; conjunto de datos: cuello uterino) por grupo de edad
para cuatro países diferentes [19, 38].
1. Grafique los datos y analice cualquier característica destacada.
2. Explique por qué es útil un desplazamiento al ajustar un glm a los datos.
3. Ajuste un glm de Poisson con edad y país como variables explicativas. Produzca la gráfica de residuos contra los valores ajustados y evalúe el modelo.
4. Ajuste el modelo cuasi-Poisson correspondiente. Producir la trama de residuos
contra los valores ajustados, y evaluó el modelo.
5. Ajuste el glm binomial negativo correspondiente. Produzca la gráfica de residuos contra valores ajustados y evalúe el modelo.
6. ¿Qué modelo parece apropiado, si alguno?

1.R/

```{r}
library(GLMsData)
data(cervical)
# Acá Wyears es T
str(cervical)


## Inciso 1

plot(Deaths ~ Country, data = cervical)
plot(Deaths ~ Age, data = cervical)
#plot(Deaths ~ jitter(Wyears), data = cervical)#Para el tercer gráfico, hace falta mencionar como se verán los años de exposición para este ajuste, será la suma de los años a los que las mujeres estuvieron expuesta en conjunto al cáncer(para hacer un conteo de muertes por años de exposición)
```


Del primer gráfico, se ve que el país con un mayor número absoluto de muertes es Inglaterra-Gales, mientras que el conteo para Bélgica es el menor, seguido de Italia y luego de Francia.

En el segundo gráfico se observa que hay un relación positica en tre el número de muertes y la edad, la mediana crece consistentemente, pero también se observa como el tercer cuartil crece bastante en cada caso. 




```{r}
# library(tidyverse)
# 
# 
# 
# # Cantidad de muertes por cada país
# cant <- cervical %>% group_by(Country) %>% summarise(Deaths= sum(Deaths))
# 
# plot(cant$Deaths ~ cant$Country)
# 
# 
# 
# cervical$Rate <- cervical$Deaths / cervical$Wyears
# matplot( xtabs( Rate ~ Age+Country, data=cervical), pch=1:4, lty=1:4,
# type="b", lwd=2, col="black", axes=FALSE,
# xlab="Age group", ylab="Deaths/yearsexposure")
# axis(side=1, at=1:4, labels=levels(cervical$Age))
# axis(side=2, las=1); box()
# legend("topleft", col="black", pch=1:4, lwd=2, lty=1:4, merge=FALSE,
# legend=c("Belgium","EngWales","France","Italy" ) )
# 
# 
# 
# 
# # Cantidad de muertes por cada rango de edad
# cant <- cervical %>% group_by(Age) %>% summarise(Deaths= sum(Deaths))
# 
# plot(cant$Deaths ~ cant$Age)
```



Los gráficos anteriores confirman lo comentado al inicio sobre país y rango de edad. 


```{r}
data(cervical)
 cervical$AgeNum <- rep( c(25, 35, 45, 55), 4)
 par( mfrow=c(2, 2))
 ### Part 1
 with( cervical, {
plot( Deaths/Wyears ~ AgeNum, type="n")
lines(Deaths/Wyears ~ AgeNum, lty=1,
subset=(Country==unique(Country)[1]) )
lines(Deaths/Wyears ~ AgeNum, lty=2,
subset=(Country==unique(Country)[2]) )
lines(Deaths/Wyears ~ AgeNum, lty=3,
subset=(Country==unique(Country)[3]) )
lines(Deaths/Wyears ~ AgeNum, lty=4,
subset=(Country==unique(Country)[4]) )
legend("topleft", lty=1:4, legend=unique(cervical$Country) )
})
```
Tendencia de muerte por país. Se ve que es creciente con forme a la edad

2.R/

Para dar cuenta de la exposición. Es una buena idea trabajar con un offset porque no se tiene información como por ejemplo la cantidad de mujeres expuestas para trabajar una binomial, si no que se tiene una medida de tiempo. Offset es una variable que se utiliza en el análisis de regresión de Poisson. Este análisis se utiliza siempre que los datos se registran durante un período observado.

3.R/

Se usumirá independencia entre el país y la edad


```{r}
### Part 3
 cc.m0 <- glm( Deaths ~ offset(log(Wyears)) + Age + Country,
data=cervical, family=poisson )
 plot( rstandard(cc.m0) ~ fitted(cc.m0), main="Poisson glm" )
```

Interpretacion de Leandro: Se presenta uns buena significancia de las variables, pero como la devianza da mucho más alta que los grados de libertad (habiendose cumplido la regla empírica de los yi ser mayores todos a 3 ) se tiene un indicador claro de sobredispersión. Pero se verá también el gráfico de residuos.

Majo: No se ve una alta varianza y se observa que de -20 para arriba se encuentra las variables y se ve un posible outlierentre 0 y 500

```{r}
fit10.11quasi <- glm( Deaths ~ offset( log(Wyears) ) + Country +Age,
family="quasipoisson", data=cervical)
summary(fit10.11quasi)

plot(fit10.11quasi)



set.seed(27)
q_res <- resid(fit10.11quasi) 
scatter.smooth(q_res ~ fit10.11quasi$fitted.values)

```
```{r}

set.seed(27)
q_res1 <- qresid(fit10.11quasi) 
scatter.smooth(q_res1 ~ fit10.11quasi$fitted.values)
```



5.R/


```{r}
## Inciso 5

library(MASS)




fit10.11binneg <- glm.nb( Deaths ~ offset(log(Wyears)) + Country +Age, data=cervical)
fit10.11binneg <- glm.convert(fit10.11binneg)
summary(fit10.11binneg)


plot(fit10.11binneg)


set.seed(27)
q_res <- resid(fit10.11binneg) 
scatter.smooth(q_res ~ fit10.11binneg$fitted.values)
```
Todos los modelos parecen tener un gran valor atípico negativo, pero
claramente el modelo de Poisson no acomoda la variación correctamente.

6.R/

Se puede observar que entre el modelo de poisson y el negativo binomial, el aic más pequeño es ek negativo binomial, entonces es un mejor modelo. Además que la devianza es bastante alta en comparación a los gradis de libertad, en el modelo quasi y el poisson. 

10.16. Un experimento [21] comparó la densidad de aves del sotobosque en un
serie de sitios en dos áreas a cada lado de una cerca a prueba de ganado, data conjunto: pastoreo). Un lado tenía un pastoreo limitado (principalmente de herbívoros nativos) y el otro estaba fuertemente pastoreado por herbívoros salvajes, en su mayoría caballos.
Se registraron conteos de aves en los sitios a ambos lados de la cerca (el "antes"
mediciones). Luego se eliminaron los herbívoros y se registraron los conteos de aves.
de nuevo (las medidas 'después'). Las medidas son el número total de
Aves que buscan alimento en el sotobosque observadas en tres estudios de 20 min de cuadrantes de 2 ha.
1. Grafique los datos y explique las características importantes.
2. Ajuste un glm de Poisson con el componente sistemático Birds ~ When * Pasto,
asegurando un análisis de diagnóstico.
3. Demostrar que existe sobredispersión. Demostrar calculando la media
y varianza de cada combinación de las variables explicativas.
4. Ajuste un modelo cuasi-Poisson.
5. Ajuste un glm binomial negativo.
6. Compare los tres modelos ajustados para determinar un modelo adecuado.
7. Interpretar el modelo final.

1.R/
```{r}
library(GLMsData)
data(grazing)
# Acá Wyears es T
str(grazing)


## Inciso 1

plot(Birds ~ When, data = grazing)
plot(Birds ~ Grazed, data = grazing)
```

Del segundo gráfico, se ve que entre los hervíboros, el que tiene un mayor número absoluto de aves es el nativo, mientras que el conteo para el salvaje es el menor.

En el primer gráfico se ve que se observó un mayor conteo después, en comparación de antes


2.R/

```{r}
modelo_Poisson<-glm(formula = Birds ~ Grazed * When, data = grazing, family = poisson())
```
```{r}
medidas <- influence.measures(modelo_Poisson)
colSums(medidas$is.inf)
which(medidas$is.inf[,7])
```
  Tiene 3 outliers y eso es malo
3.R/
La devianza es demasiado alta en comparación con los grados de libertad, entonces hay sobredispersion

4.R/

```{r}
modelo_PoissonQuasi<-glm(formula = Birds ~ Grazed*When, data = grazing, family = quasipoisson())
medidas1 <- influence.measures(modelo_PoissonQuasi)
colSums(medidas1$is.inf)
which(medidas1$is.inf[,7])
```
Devianza muy alta en comparación a sus grados de libertad

5.R/

```{r}
modelo_Poissonnb<-glm.nb( formula = Birds ~ Grazed*When, data = grazing)
medidas2 <- influence.measures(modelo_Poissonnb)
colSums(medidas2$is.inf)
which(medidas2$is.inf[,7])
```
Se puede observar que la devianza no es tan alta como los grados de libertad, entonces no se ve tan claro la sobredispersion.

6.R/Se ve que es mejor el binomial negativo, por su devianza

7.R/ 
Se observa una devianza moderada, en comparación a los grados de libertad, además que tiene una mejor aic, un más baja.



#####################
```{r}
c("contr.treatment", "contr.treatment")
 Orden_Mary_Joseph <- c("Green", "Cons", "Labour", "LibDem", "Other")
 belection$Party <- ordered(belection$Party, levels=c(Orden_Mary_Joseph))
 levels(belection$Party)
 contrasts(belection$Party)
```


