---
title: "Ejer"
author: "Maria Jose Corea"
date: "2022-10-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

2.16 Un estudio de bebés planteó la hipótesis de que los bebés tardarían más en
aprender a gatear en los meses más fríos porque la ropa extra restringe su
movimiento. Entre 1988 y 1991, la primera edad de gateo de los bebés y el promedio
se registró la temperatura mensual seis meses después del nacimiento (cuando “los bebés presumiblemente entran en la ventana de preparación locomotora”; p. 72). Los padres
informaron el mes de nacimiento y la edad en que su bebé se arrastró o gateó por primera vez
distancia de cuatro pies en un minuto. Los datos fueron recolectados en la Universidad de
Denver Infant Study Center sobre 208 niños y 206 niñas, y resumido por
el mes de nacimiento (Tabla 2.10; conjunto de datos: rastreo).
1. Trazar los datos. ¿Qué suposiciones, si las hubiere, parecen violarse?
2. Explique por qué un modelo de regresión ponderado es apropiado para los datos.
3. Ajuste un modelo de regresión lineal ponderado a los datos e interprete el
coeficientes de regresión.
4. Probar formalmente la hipótesis propuesta por los investigadores.
5. Encuentre un intervalo de confianza del 90 % para la pendiente de la línea ajustada, y
interpretar.
6. Ajuste el modelo de regresión no ponderado, luego trace ambas líneas de regresión en
una trama de los datos. Comenta las diferencias.
7. Calcule los intervalos de confianza del 95 % para los valores ajustados de la
línea de regresión ponderada, y también grafíquelos.
8. Interpreta el modelo.


```{r}
Babies <- read.csv("~/GitHub/II-2022/Modelos Lineales/Base.txt")
 library(GLMsData)
#Babies<-data(crawl)

colnames(Babies) <- c('Mes', 'PromedioSemanas','Frecuencia', 'PromedioTemperatura')


```

1.R\

```{r}
#qqnorm(Babies$Monthly.average.temperature.six.months.after.birth..â..F., pch = 1, frame = FALSE)
#qqline(Babies$Monthly.average.temperature.six.months.after.birth..â..F., col = "steelblue", lwd = 2)
#qqnorm(Babies$PromedioTemperatura, pch = 1, frame = FALSE)
#qqline(Babies$PromedioTemperatura, col = "steelblue", lwd = 2)


p <- lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)

plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p), lty=1, lwd=2)
```
Al realizar la comparación del promedio de semanas hasta gatear y el rpomedio de la temperatura en los siguientes 6 meses, se puede observar una relativa linealidad decreciente, es decir, que en cuanto más frío esté, menos son los reportes de que los niños gateen. Y se encuentra un outlyer entre 50 y 60.

2.R\

Porque la regresión ponderada se puede utilizar para corregir la heterocedasticidad. En un procedimiento de regresión ponderada, se otorga más peso a las observaciones con una varianza más pequeña porque estas observaciones brindan información más confiable sobre la función de regresión que aquellas con varianzas grandes. Observemos que la varianza de las observaciones, asimismo la desviación estándar y un histograma para ver si se ve normalidad.

Como son promedios y deben considerarse que los promedio son toamdos de disntintas poblaciones.

```{r}
#var(Babies$PromedioTemperatura)
#sd(Babies$PromedioTemperatura)
#hist(Babies$PromedioTemperatura, breaks = 12)
```
3.R/

```{r}

mod_leo <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies, weights = Frecuencia)

coef(mod_leo)
```
Un aumento en una unidad de temperatura, que es unica covariable y provoca una disminucuion de mas 0.75 en promedio en la edad promedio de gateo, amnteniendo las demás variables constante. Un unidad de la tempratura sube, indica que el promedio de la edad promedio baja en o.075, nomina lmente, funcio de enlacio que es la identidad.
Un aumento de la temperatura proboca una disminucion de apro de 0.075 en promedio de la edad promedio,  como estamps viedno la esperanza, que estamos viendo mu, que es la esperanza de Y.

Es importante ver que al menos sale negativo el coeficiente, que es lo que espera el estudio,puesto que tienen una relación negativa.

4. R/

```{r}
summary(mod_leo)
```


Nos salio una prueba de t, con un nivel de 5% de confianza, si se rechaza y con un 1% de significancia, no se rechaza.


5.R/

El IC95% aporta al lector la precisión estadística. Por «precisión estadística», se refiere a la incertidumbre introducida por los métodos de muestreo. Es un intervalo bastante pequeño, lo cual sin ser muy conservadores, se encuentra el rango de error.

```{r}
confint(mod_leo, level = 0.9)

```

6.R/

```{r}

mod_leo2 <-  lm(PromedioSemanas ~ PromedioTemperatura, data=Babies)

coef(mod_leo)

```

Un aumento en una unidad de temperatura, que es unica covariable y provoca una disminucuion de mas 0.75 en promedio en la edad promedio de gateo, amnteniendo las demás variables constante. Un unidad de la tempratura sube, indica que el promedio de la edad promedio baja en 0.077, nomina lmente, funcio de enlacio que es la identidad.
Un aumento de la temperatura proboca una disminucion de apro de 0.077 en promedio de la edad promedio,  como estamps viedno la esperanza, que estamos viendo mu, que es la esperanza de Y.

Es importante ver que al menos sale negativo el coeficiente, que es lo que espera el estudio,puesto que tienen una relación negativa.

Entonces baja un 0.002, o sea el impacto es mayor.

```{r}

plot( PromedioSemanas ~ PromedioTemperatura, data=Babies, las=1,
xlab="Promedio Temperatura", ylab="Promedio semanas" )
abline( coef(p),col="red", lty=1, lwd=2)
abline( coef(mod_leo),col="blue", lty=1, lwd=2)
```

Asimismo, se puede ver mediante el gráfico una diferencia no tan abismal.

7.R/

```{r}
library(ggplot2)
ggplot(data = Babies, mapping = aes(x = Babies$PromedioTemperatura, y = Babies$PromedioSemanas)) + geom_point() + geom_smooth(method = lm)
```

No reduce muy significativamente el intervalo de confianza, siendo un 5% más conservadores, esto probablemente por la variabilidad de las observaciones
```{r}
confint(mod_leo, level = 0.95)

```
```{r}
new.base <- data.frame(PromedioTemperatura = seq(30,50,2))
out <- predict(mod_leo, newdata = new.base, se.fit = TRUE)
names(out)

tstar <- qt(df=mod_leo$df.residual, p=0.975 ) # For a 95% CI
ci.lo <- out$fit - tstar*out$se.fit
ci.hi <- out$fit + tstar*out$se.fit
CIinfo <- cbind( Lower=ci.lo, Estimate=out$fit, Upper=ci.hi)
CIinfo

 newA <- seq( min(Babies$PromedioTemperatura), max(Babies$PromedioTemperatura), length=11)

 plot( Babies$PromedioSemanas~Babies$PromedioTemperatura, data=Babies)
 abline(coef(mod_leo), lty=1)
lines(ci.lo~newA, lty=2)
lines(ci.hi~newA, lty=2)
```



8.R/

Como rompe con el supuesto de variabilidad nula, entonces se necesita un ajuste mediante los pesos, el cual no mejora significativamente la regresión, lo importante es notar es que si se logra la relación inversa con lo propuesto mediante la hip nula.


3.15. Un estudio de bebés [4] planteó la hipótesis de que los bebés tardarían más en
aprender a gatear en los meses más fríos porque la ropa extra restringe su
movimiento (conjunto de datos: rastreo). Los datos y una descripción más completa se dan en
Problema 2.16 (pág. 87). En ese problema, se ajustó un modelo de regresión lineal
a los datos
1. Realice un análisis de diagnóstico del modelo de regresión lineal ajustado.
2. Identifique las observaciones influyentes o los valores atípicos.
3. Suponga que algunos de los bebés fueran mellizos. ¿Qué suposición sería
violado por la inclusión de estos bebés en el estudio? ¿Crees que esto
tendría implicaciones prácticas

1.R/
```{r}
rstandard(p)#residual estandarizado
fitted(p) #Este ejemplo demuestra cómo encontrar los valores ajustados de un modelo de regresión lineal usando la función added().
cooks.distance(p) #La distancia de Cook es un resumen de cuánto cambia un modelo de regresión cuando se elimina la i-ésima observación
 scatter.smooth( rstandard(p) ~ fitted(p) )
 qqnorm( rstandard(p) ); qqline( rstandard(p) )
 plot( cooks.distance(p), type="h")
 plot( rstandard(p) ~ Babies$PromedioTemperatura)
 
```
 
2.R/

```{r}
influence.measures(p)
#rowSums(influence.measures(p)$is.inf)
```
 3.R/ 
 
 Hay una tendencia lineal, hay presencia de 3 outliers, el de la posición 2, 3 y 5, o se en febrero, marzo y mayo. Son de influencia.
 
 
5.25. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [2, 9]. El número de bloques utilizados y el tiempo empleado
fueron registrados (Tabla 2.12; conjunto de datos: bloques). En este problema, sólo considere
el número de bloques utilizados y y la edad del niño x.

1. Grafique el número de bloques usados contra la edad del niño.

2. A partir de la gráfica y la comprensión de los datos, responda las dos preguntas para estos datos y, por lo tanto, proponga un glm para los datos.

1.R/

```{r}
library("GLMsData") 
data(blocks)

 #par(mfrow=c(1, 2))
 #plot(jitter(Number)~Age, data=blocks)
 #plot( Number~cut(Age, 3), data=blocks)

plot( jitter(Number)~Age,  data=blocks, las=1,
xlab="Número de bloques", ylab="Edad del niño" )
```
1. ¿Qué distribución de probabilidad es apropiada? La respuesta determina la
componente aleatoria del modelo. La elección de la distribución de probabilidad
pueden ser sugeridos por los datos de respuesta (por ejemplo, proporciones de un
total sugieren una distribución binomial), o el conocimiento de cómo la varianza
cambia con la media.

```{r}
var(blocks$Number)
mean(blocks$Number)
```
Varianza y media cercana, como una distribución poisson

2. ¿Cómo se relacionan las variables explicativas con la media de la respuesta?
¿? La respuesta sugiere el componente sistemático del modelo. glms
asumir una función que une el predictor lineal η = β0 + p
j=1 βjxj a
la media μ, como log μ = η por ejemplo. Es decir, glms son regresión
modelos lineales en los parámetros.

se relaciona de una manera similar

6.10. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [3, 6]. El número de bloques utilizados y el tiempo empleado
fueron registrados (conjunto de datos: bloques). En este problema, sólo considere el número
de bloques utilizados y y la edad del niño x. En el Problema 5.25, un glm fue
propuesta para estos datos.
1. Ajuste este glm usando r y escriba el modelo ajustado.
2. Determinar el error estándar para cada parámetro de regresión.
3. Calcule la desviación residual.

1.R/

```{r}
data(blocks)
 m1 <- glm(Number~Age, data=blocks, family=poisson)

```
2.R/

```{r}

deviance(m1)
```

3.R/

```{r}
summary(m1)
```
Que quiere decir?


7.4. Se pidió a los niños que construyeran torres tan altas como pudieran a partir de cubos
y bloques cilíndricos [3, 7]. El número de bloques utilizados y el tiempo empleado
fueron registrados (conjunto de datos: bloques). En este problema, sólo considere el número
de bloques utilizados y y la edad del niño x. En el problema 6.10, se ajustó un glm
para estos datos.
1. Use una prueba de Wald para determinar si la edad parece necesaria en el modelo.
2. Use una prueba de puntuación para determinar si la edad parece necesaria en el modelo.
3. Usar una prueba de razón de verosimilitud para determinar si la edad parece necesaria en el
modelo.
4. Compare los resultados de las pruebas de Wald, puntuación y razón de verosimilitud. comentario.
5. ¿Se espera que la aproximación del punto de silla sea precisa? Explique.
6. ¿Se espera que el teorema del límite central sea exacto? Explique.
7. Halle los intervalos de confianza de Wald al 95 % para los coeficientes de regresión.
8. Grafique el número de bloques usados contra la edad y muestre la relación
descrito por el modelo ajustado. Traza también las rectas que indican el debajo y
sobre al 95% de IC para estos valores ajustados.

```{r}
data(blocks); library(statmod)
 m1 <- glm(Number~Age, data=blocks, family=poisson)
 m0 <- update(m1, .~1)
 
```

1.R/
```{r}
summary(m1)
(z.Wald <- coef(summary(m1))[2, 3])
 (P.Wald <- coef(summary(m1))[2, 4])
```
La edad tiene una significancia de 0.001, estonces sí es necesaria

2.R/

```{r}
( z.score <- glm.scoretest(m0, blocks$Age))#Calcula las estadísticas de las pruebas de puntuación (estadísticas z) para agregar covariables a un modelo lineal generalizado.
( P.score <- 2*(1-pt(abs(z.score), df=df.residual(m1)))) #La función pt devuelve el valor de la función de densidad acumulada (cdf) de la distribución t de Student dada una determinada variable aleatoria x y grados de libertad df
#por ser t student y su simetría ent quedaría = 2(1 − Pr {zscore < grados de libertad}).

```
Pues con este modelo, se de muestras que es de significancia la edad

3.R/

```{r}
anova(m1)
anova(m1, test="Chisq")
(chisq.LRT <- anova(m1)[2, 2])
( P.LRT <- anova(m1, test="Chisq")[2, 5])
```
También se demuestra con un 0.001 la significancia de la edad con la verosimilitud
4.R/
```{r}
 c(z.Wald, z.score, sqrt(chisq.LRT))
 round(c(P.Wald, P.score, P.LRT), 4)
 
 
```
Se puede observar que con la prueba de likehood, pues la significancia de la edad es la más cercana a 0, o sea la que más ve relevante la edad

5.R/ Para un glm de Poisson, se espera que la aproximación del punto de silla sea suficiente si el
menor y ≥ 3; aquí el mínimo es 3, así que se espera que la aproximación del punto de silla esté bien. 
```{r}
min(blocks$Number)
```

6.R/Para un glm de Poisson, se espera que la aproximación teorema del limite central sea suficiente si es y ≥ 5; aquí el mínimo es 3, por lo que la aproximación teorema del limite central 
puede ser insuficientemente preciso.

7.¿?

8.R/
```{r}
 newA <- seq( min(blocks$Age), max(blocks$Age), length=100)
 newB <- predict( m1, newdata=data.frame(Age=newA), type="response",
se.fit=TRUE)
plot( jitter(Number)~Age, data=blocks)
 lines(newB$fit ~ newA, lwd=2)
 t.star <- qt(p=0.975, df=df.residual(m1))
 ci.lo <- newB$fit - t.star * newB$se.fit
 ci.hi <- newB$fit + t.star * newB$se.fit
 lines(ci.lo~newA, lty=2)
 lines(ci.hi~newA, lty=2)
```


