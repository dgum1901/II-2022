---
output:
  pdf_document: 
    toc_depth: 0
    includes:
      in_header: preambulo.tex
      before_body: titulo.tex
documentclass: memoir
classoption: oneside
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
require("knitcitations")
require("bibtex")
library(rmdformats)
library(readxl)
library(dplyr)
library(plyr)
library(fOptions)
library(ggplot2)
library(kableExtra)
library(extrafont)
library(scales)
library(xtable)
library(corrplot)
options(max.print="75")
opts_chunk$set(echo=FALSE, 
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)

```

\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}
\lhead{CA-409 Distribución de Pérdidas}
\rhead{Bitácora \thechapter}
\fancyfoot[C]{\thepage}

\tableofcontents*

\newpage
\chapter{Bitácora I}


\section{Sobre la base de datos}

```{r}
base <- read.csv('~/GitHub/II-2022/Distribución de pérdidas/Fire Incidents Data.csv')

perd <- base$Estimated_Dollar_Loss
#Los elementos de la base donde no se cuantificaron perdidas no interesan
base <- base[!is.na(perd),]
perd <- perd[!is.na(perd)]


```


```{r}
p <- read.csv('~/GitHub/II-2022/Distribución de pérdidas/columnas.txt',sep = ',', fileEncoding = "UTF-8")

knitr::kable(p, caption = "Descripción completa de la base", longtable = TRUE) %>%
  column_spec(2, width = "7cm") %>% footnote(general = 'Fuente: Elaboración propia', general_title = '') %>%
  kable_styling(latex_options = c("repeat_header"),
                repeat_header_continued = "Continua en siguiente pag",
                repeat_header_text = "\\textit{(Continuación)}"
                )

```

\chapter{Bitácora II}

Dado que la pregunta de investigación se centra en encontrar las bases que generan que un siniestro de tipo incendio sea de mayor cuantía en cuanto a pérdidas, por lo que este primer cuadro analiza la correlacion entre el log-estimado de perdidas (podria ser perfectamente el estimado regular) y las variables numéricas, para ello se utiliza select, y se genera una nueva variable numérica que corresponde a la diferencia entre el tiempo de notificación y el tiempo de llegada de las autoridades al lugar del siniestro.

En cuanto a la metodología para obtener la correlación, y pensando más que todo en que los datos podrían no necesariamente obedecer a modelos estríctamente lineales, se utilizó 

```{r}
base$logEstimado <- log(base$Estimated_Dollar_Loss)
base$logEstimado <- case_when(base$Estimated_Dollar_Loss == 0 ~ 0,
                              TRUE ~ log(base$Estimated_Dollar_Loss))

base$TFS_Alarm_Time <- as.POSIXct(base$TFS_Alarm_Time, format = "%Y-%m-%dT%H:%M:%S")
base$TFS_Arrival_Time <- as.POSIXct(base$TFS_Arrival_Time, format = "%Y-%m-%dT%H:%M:%S")

base$tiempoAtencion <- as.numeric(difftime(base$TFS_Arrival_Time, base$TFS_Alarm_Time))


# El pairwise.complete.obs es para garantizar que tome todas las observaciones
# completas por pares, para más consultas favor consultarme
p <- base %>% dplyr::select(is.numeric & !Estimated_Dollar_Loss) %>% cor(use = "pairwise.complete.obs", method = "spearman")


#xtable(tibble(colnames(p)))
colnames(p) <- 1:14
rownames(p) <- 1:14
xtable(p)

#corrplot(p)

```

```{r}
#Este código exporta el gráfico en formato PDF
pdf("corrPlor.pdf")
corrplot(p)
dev.off()

```


Para iniciar hablando de la distribución del estimado de pérdidas.

```{r}
p <- tibble(summary(base$logEstimado), summary(base$Estimated_Dollar_Loss))
p <- rbind(p, c(sd(base$logEstimado), sd(base$Estimated_Dollar_Loss)))
p <- rbind(p, c(IQR(base$logEstimado), IQR(base$Estimated_Dollar_Loss)))
colnames(p) <- c('Log pérdida estimada', 'Pérdida estimada')
rownames(p) <- c('Mínimo', '1er cuartil','Mediana','Promedio','Tercer cuartil','Máximo', 'Desviación', 'IQr')
IQR(base$logEstimado)
xtable(p)
```


```{r}
p <-
  aggregate(
    base$Estimated_Dollar_Loss,
    by = list(Category = base$Smoke_Alarm_at_Fire_Origin),
    FUN = sum
  )
p$Frecuencia <- count(base$Smoke_Alarm_at_Fire_Origin)$freq
p$Media <- p$x/p$Frecuencia


#p <- p[p$x > out,]
p <- p[order(-p$Media),]
xtable(p)
```


```{r}

p <-
  aggregate(
    base$Estimated_Dollar_Loss,
    by = list(Category = base$Property_Use),
    FUN = sum
  )
p$Frecuencia <- count(base$Property_Use)$freq
p$Media <- p$x/p$Frecuencia

#p <- p[p$x > out,]

a <- p[order(-p$x),]

a <- a[1:10,]

xtable(a)

a <- p[order(-p$Media),]

a <- a[1:10,]

xtable(a)



```





\section{Graficos}

```{r}

out <- quantile(perd, 0.95) #cuantil del 95 por ciento
grafico0 <-
  ggplot(base, aes(x = Estimated_Dollar_Loss)) + 
  geom_histogram(color =
                   "darkblue", fill = "lightblue") + theme_bw() +
  labs(
    y = "Frecuencia",
    x = "Pérdida en escala regular",
    title = "Gráfico 1: Histograma en escala regular de las pérdidas",
    caption = "Fuente: Elaboración propia"
  )

grafico0


grafico1 <-
  ggplot(base, aes(x = log(Estimated_Dollar_Loss))) + 
  geom_histogram(color =
                   "darkblue", fill = "lightblue") + theme_bw() +
  labs(
    y = "Frecuencia",
    x = "Pérdida en escala logarítmica",
    title = "Gráfico 1: Histograma en escala logarítmica de las pérdidas",
    caption = "Fuente: Elaboración propia"
  )

grafico1

base$Extremo <- perd >= out

grafico2 <-
  ggplot(data = base) + geom_bar(
    mapping = aes(x = Extremo),
    color = c('blue', 'red'),
    fill = c('lightblue', 'pink'),
    width = 0.5,
    na.rm = TRUE
  ) + theme_bw() +
  labs(
    y = "Frecuencia",
    x = "Cuantil",
    title = "Gráfico 1: Frecuencia del estimado de pérdidas de acuerdo al cuantil 0.95",
    caption = "Fuente: Elaboración propia"
  ) +
  scale_x_discrete(labels = c("Menor 95%", "Mayor o igual 95%"))
grafico2


p <-
  data.frame(
    Name = c("Masa cuantil menor a .95", "Masa cuantil mayor o igual a .95"),
    Amount = c(sum(perd[perd < out]), sum(perd[perd >= out]))
  )

grafico3 <- ggplot(p, aes(x = Name, y = Amount)) + geom_bar(
  stat = "identity",
  color = c('blue', 'red'),
  fill = c('lightblue', 'pink'),
  width = 0.5,
  na.rm = TRUE
) + theme_bw() +
  labs(
    y = "Masa de la pérdida",
    x = "Cuantil",
    title = "Gráfico 3: Masa del estimado de pérdidas de acuerdo al cuantil 0.95",
    caption = "Fuente: Elaboración propia"
  ) + scale_y_continuous(labels = comma) + scale_x_discrete(limits = p$Name)
grafico3

```


```{r}
pdf("graf0.pdf")
grafico0
dev.off()
```



\section{Bitacora 3}

Dado que se utiliza el ajuste con la función fevd, estos son los únicos resultados


```{r}
p <- base$logEstimado[base$Extremo]

#c("GEV", "GP", "PP", "Gumbel", "Exponential")

gev <- fevd(p,type="GEV", method = 'MLE') #Generalized Extreme Value
s <- summary(gev)
( gev.comp <- c(s$AIC[[1]],s$BIC[[1]], -s$nllh) )

gp <- fevd(p,type="GP", threshold = log(out), method = 'MLE') #Generalized Pareto
s <- summary(gp)
( gp.comp <- c(s$AIC[[1]],s$BIC[[1]], -s$nllh) )

gumbel <- fevd(p,type="Gumbel", method = 'MLE') #Gumbel
s <- summary(gumbel)
( gumbel.comp <- c(s$AIC[[1]],s$BIC[[1]], -s$nllh) )

pp <- fevd(p,type="PP", threshold = log(out), method = 'MLE') #Poisson Process
s <- summary(pp)
( pp.comp <- c(s$AIC[[1]],s$BIC[[1]], s$nllh) )

exponencial <- fevd(p,type="Exponential", threshold = log(out), method = 'MLE') #exponencial
s <- summary(exponencial)
( exponencial.comp <- c(s$AIC[[1]],s$BIC[[1]], -s$nllh) )

df <-
  data.frame(
    GEV = gev.comp,
    GP = gp.comp,
    Gumbel = gumbel.comp,
    PP = pp.comp,
    Exponencial = exponencial.comp
  )
rownames(df) <- c('AIC','BIC', 'Log-verosimilitud')
#xtable(df)
df

```

Ahora se busca ajustar Weibull, Frechet y Beta

```{r}


library(fitdistrplus)
weibull <- fitdist(p, "weibull")
weibull.comp <- c(weibull$aic, weibull$bic, weibull$loglik)

library(extraDistr)
frechet<-fitdist(p,"frechet", start = list( lambda = 1, mu = 1, sigma = 1))
frechet.comp <- c(frechet$aic, frechet$bic, frechet$loglik)

# dbeta_d <- function(x, alpha = -1, theta = 1){
#   #alpha * (-x)^(-alpha-1)
#   -alpha / theta * (-(x-theta)/theta)^(-alpha-1)
# }
beta <- fitdist(p, 'betapr', start = list(  shape1=1, shape2=1))

# beta <- fitdist(p, dbeta_d, start = list( alpha = 3000 , theta = 300))
beta.comp <- c(beta$aic, beta$bic, beta$loglik)

df <-
  data.frame(
    Weibull = weibull.comp,
    Frechet = frechet.comp,
    Beta = beta.comp
  )
rownames(df) <- c('AIC','BIC', 'Log-verosimilitud')
xtable(df)
df

```
Reajustamos las primeras funciones con fitdist para hacer más facil la graficacion
```{r}

gev2 <- fitdist(p, "gev", start = list(mu = 0, sigma = 1, xi = 2.302585 ))
gev2.comp <- c(gev2$aic, gev2$bic, gev2$loglik)

library(actuar)
gp2 <- fitdist(p, 'genpareto' , start=list(shape1 = 1, shape2=1))

gp2.comp <- c(gp2$aic, gp2$bic, gp2$loglik)
denscomp(gp2)


gumbel2 <- fitdist(p, 'gumbel', start=list(alpha = 0, scale = 1))
gumbel2.comp <- c(gumbel2$aic, gumbel2$bic, gumbel2$loglik)

exponencial2 <- fitdist(p, 'exp')
exponencial2.comp <- c(exponencial2$aic, exponencial2$bic, exponencial2$loglik)

df <-
  data.frame(
    GEV = gev2.comp,
    GP = gp2.comp,
    Gumbel = gumbel2.comp,
    Exponencial = exponencial2.comp
  )
rownames(df) <- c('AIC','BIC', 'Log-verosimilitud')
xtable(df)

grafico4 <- denscomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), main = 'Histograma contra cada densidad', xlab = 'log-precio', ylab= 'Densidad')
grafico5 <- qqcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), xlab = 'Cuantil teórico', ylab = 'Cuantil empírico')
grafico6 <- cdfcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), main = 'CDF empírico y teórico', xlab = 'log-precio')
grafico7 <- ppcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), xlab = 'Probabilidad teórica', ylab = 'Probabilidad empírica')


pdf("graf4.pdf")
denscomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), main = 'Histograma contra cada densidad', xlab = 'log-precio', ylab= 'Densidad')
dev.off()
pdf("graf5.pdf")
qqcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), xlab = 'Cuantil teórico', ylab = 'Cuantil empírico')
dev.off()
pdf("graf6.pdf")
cdfcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), main = 'CDF empírico y teórico', xlab = 'log-precio')
dev.off()
pdf("graf7.pdf")
ppcomp(list(weibull, frechet, beta, gev2, gp2,gumbel2, exponencial2), xlab = 'Probabilidad teórica', ylab = 'Probabilidad empírica')
dev.off()
```



Analisis diagnostico

```{r}
#se comparan los deos mejores modelos

comparacion <- gofstat(f = list(frechet, gumbel2, gev2))
comparacion

df <- tibble('Kolgomorov-Smirnoff' = comparacion$ks, 'Anderson-Darling' = comparacion$ad, 'Chi-Cuadrado'=comparacion$chisq)

rownames(df) <- c('Frechet','Gumbel','GEV')


xtable(df)
```



```{r}
descdist(p, discrete = FALSE)
```




\printbibliography
